{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecsysContentBased_2019.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hernan4444/diplomado-sistemas-recomendadores/blob/master/Diplomado_Alumno_2019_Sistemas_Recomendadores_3_Content_Based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC-ceGb8LRLT",
        "colab_type": "text"
      },
      "source": [
        "# Práctica de Sistemas Recomendadores 3: Content based"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mACJbcW8T35p",
        "colab_type": "text"
      },
      "source": [
        "En este práctico, volveremos a utilizar la biblioteca de Python [sklearn](https://scikit-learn.org/stable/), para aprender sobre 2 algoritmos para recomendación basado en contenidos y de unas herramientas para preprocesar los textos. En particula, este practico verá:\n",
        "\n",
        "* TF-IDF\n",
        "* Word Embeddings\n",
        "* Uso de Stop Words\n",
        "\n",
        "**Ayudantes**: Manuel Cartagena, Andrés Carvallo y Patricio Cerda\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKAqmo5IdQFI",
        "colab_type": "text"
      },
      "source": [
        "# Actividad 1\n",
        "\n",
        "Antes de empezar con la actividad, responder la siguiente pregunta con lo visto en clases\n",
        "\n",
        "**Pregunta:** Explique con sus palabras a qué se refiere con recomendación basada en contenido. En particular responda\n",
        "\n",
        "- ¿Qué datos se utilizan para recomendación basada en contenidos?\n",
        "- Mencione un ejemplo donde sea factible utilizar este tipo de recomendación y justifique.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvDxjWvUdcv8",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta:** COMPLETAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFpEoacrMwQx",
        "colab_type": "text"
      },
      "source": [
        "# Descargando la información\n",
        "\n",
        "Vaya ejecutando cada celda presionando el botón de **Play** o presionando Ctrl+Enter (Linux y Windows) o Command+Enter (Macosx) para descargar las bases de datos.\n",
        "\n",
        "*   Recursos:\n",
        "  * `dictionary.p`\n",
        "  * `dictionary-stemm.p`\n",
        "  * `tfidf_model.p`\n",
        "  * `tfidf_model-stemm.p`\n",
        "*   Dataset:\n",
        "  *  `corpus1.csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUlFGZprHneQ",
        "colab_type": "code",
        "outputId": "f3c48909-c6a3-437e-cb1d-fcfe3ff96299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Descarga de recursos\n",
        "!curl -L -o 'resources.tar.gz' 'https://github.com/PUC-RecSys-Class/Syllabus/blob/master/Practico%204/files/resources.tar.gz?raw=true'\n",
        "\n",
        "# Descompresión del archivo\n",
        "!tar -xvf resources.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   157    0   157    0     0    447      0 --:--:-- --:--:-- --:--:--   447\n",
            "100   168  100   168    0     0    268      0 --:--:-- --:--:-- --:--:--   268\n",
            "100 1754k  100 1754k    0     0  1734k      0  0:00:01  0:00:01 --:--:-- 30.5M\n",
            "resources/\n",
            "resources/dictionary-stemm.p\n",
            "resources/dictionary.p\n",
            "resources/tfidf_model-stemm.p\n",
            "resources/tfidf_model.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN0P2xxrH0z8",
        "colab_type": "code",
        "outputId": "c1a02a73-bee3-4fef-e1c8-23ca43aefe97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Descarga del dataset\n",
        "!curl -L -o 'dataset.tar.gz' 'https://github.com/PUC-RecSys-Class/Syllabus/blob/master/Practico%204/files/dataset.tar.gz?raw=true'\n",
        "\n",
        "# Descompresión del archivo\n",
        "!tar -xvf dataset.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   155    0   155    0     0    462      0 --:--:-- --:--:-- --:--:--   464\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   166  100   166    0     0    264      0 --:--:-- --:--:-- --:--:--  162k\n",
            "\r100 3117k  100 3117k    0     0  3403k      0 --:--:-- --:--:-- --:--:-- 3403k\n",
            "./._corpus1.csv\n",
            "corpus1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJon9T5ZMwRG",
        "colab_type": "text"
      },
      "source": [
        "# Revisar archivos descargados\n",
        "\n",
        "Revisemos el _dataset_ descargado:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT11_REYOyFO",
        "colab_type": "code",
        "outputId": "35b39db1-2f3b-4836-f739-9501ff444981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "corpus_df = pd.read_csv('./corpus1.csv', sep='\\t',\n",
        "                        header=None, encoding='latin',\n",
        "                        names=['id', 'title', 'abstract'])\n",
        "corpus_df.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>Nonlinear Shape Statistics in Mumford{Shah Bas...</td>\n",
              "      <td>We present a variational integration of nonlin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100007</td>\n",
              "      <td>On the Complexity of Equilibria</td>\n",
              "      <td>We prove complexity, approximability, and inap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100008</td>\n",
              "      <td>On QoS-Aware Publish-Subscribe</td>\n",
              "      <td>This position paper addresses the issue of sup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001</td>\n",
              "      <td>Checking Mergeable Priority Queues</td>\n",
              "      <td>We present an efficient algorithm which can ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100012</td>\n",
              "      <td>Mobile Code Security by Java Bytecode Instrume...</td>\n",
              "      <td>Mobile code provides significant opportunities...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ...                                           abstract\n",
              "0  100002  ...  We present a variational integration of nonlin...\n",
              "1  100007  ...  We prove complexity, approximability, and inap...\n",
              "2  100008  ...  This position paper addresses the issue of sup...\n",
              "3   10001  ...  We present an efficient algorithm which can ch...\n",
              "4  100012  ...  Mobile code provides significant opportunities...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pSGsVQkyQoVi"
      },
      "source": [
        "Podemos ver que este _dataet: contiene 3 columnas:\n",
        "* **_id_**: identificador de cada texto\n",
        "* **_title_**: título del documento, en este caso, de un _paper_\n",
        "* **_abstract_**: primer párafo del _paper_ que es una representación abreviada, objetiva y precisa del contenido de un documento o recurso, sin interpretación crítica y sin mención expresa del autor del resumen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HU7NoDUhnYl",
        "colab_type": "text"
      },
      "source": [
        "## Preparar entorno\n",
        "Primero es necesario instalar algunas librerías previas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtscg3KuMwRL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "eec050a9-4003-4187-a760-205b7b83d002"
      },
      "source": [
        "!pip install nltk\n",
        "!pip install sklearn\n",
        "!pip install gensim\n",
        "!pip install pandas\n",
        "!pip install numpy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.16.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.3.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.4)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.205)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.205 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.205)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrZhH8Kqtx7_",
        "colab_type": "text"
      },
      "source": [
        "Luego necesitamos importar las librerías a utilizar en este práctico. No se asusten por todas las librerías, iremos explicando lo más importante a medida que se avanza en el práctico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ii2pB-LO0Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "import gensim\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "from collections import Counter\n",
        "from os.path import isfile\n",
        "from textwrap import wrap\n",
        "\n",
        "from gensim import corpora, models, similarities\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "import json\n",
        "import warnings\n",
        "import gensim \n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.options.display.max_columns = None\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUYnjZ1yOY-A",
        "colab_type": "text"
      },
      "source": [
        "## Preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo0B-gBrR9Sf",
        "colab_type": "text"
      },
      "source": [
        "Volvemos a cargar el _dataset_ a utilizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bONZGsYBR_rn",
        "colab_type": "code",
        "outputId": "fc299c89-9ffa-499e-c9d8-a18687d6a5e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "corpus_df = pd.read_csv('./corpus1.csv', sep='\\t',\n",
        "                        header=None, encoding='latin',\n",
        "                        names=['id', 'title', 'abstract'])\n",
        "corpus_df.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>Nonlinear Shape Statistics in Mumford{Shah Bas...</td>\n",
              "      <td>We present a variational integration of nonlin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100007</td>\n",
              "      <td>On the Complexity of Equilibria</td>\n",
              "      <td>We prove complexity, approximability, and inap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100008</td>\n",
              "      <td>On QoS-Aware Publish-Subscribe</td>\n",
              "      <td>This position paper addresses the issue of sup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001</td>\n",
              "      <td>Checking Mergeable Priority Queues</td>\n",
              "      <td>We present an efficient algorithm which can ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100012</td>\n",
              "      <td>Mobile Code Security by Java Bytecode Instrume...</td>\n",
              "      <td>Mobile code provides significant opportunities...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                              title  \\\n",
              "0  100002  Nonlinear Shape Statistics in Mumford{Shah Bas...   \n",
              "1  100007                    On the Complexity of Equilibria   \n",
              "2  100008                     On QoS-Aware Publish-Subscribe   \n",
              "3   10001                 Checking Mergeable Priority Queues   \n",
              "4  100012  Mobile Code Security by Java Bytecode Instrume...   \n",
              "\n",
              "                                            abstract  \n",
              "0  We present a variational integration of nonlin...  \n",
              "1  We prove complexity, approximability, and inap...  \n",
              "2  This position paper addresses the issue of sup...  \n",
              "3  We present an efficient algorithm which can ch...  \n",
              "4  Mobile code provides significant opportunities...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me-LXrP2Ocjc",
        "colab_type": "text"
      },
      "source": [
        "Luego descargamos las librerías de NLTK necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ru8N7mZ9exU",
        "colab_type": "code",
        "outputId": "1922ede6-c2b5-4353-cffa-d96a3d83e862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUTeZc5jSoIG",
        "colab_type": "text"
      },
      "source": [
        "En este momento estamos bajando un _tokenizador_ específico llamado [Punkt Sentence Tokenizer](https://kite.com/python/docs/nltk.tokenize.punkt). Este será usado a continuación para realizar una cierta tarea con los textos (no vamos a decir cual es porque una actividad es que comenten que hace dado unos ejemplos que mostramos c: ). \n",
        "\n",
        "Lo siguiente es implementar una función que transforme texto no estructurado a una lista de *tokens* procesados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25JLYOGGSOck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "af5d0205-1cee-4bc9-a8dc-549fb57e072d"
      },
      "source": [
        "def get_tokens(text):\n",
        "    # Pasar todo a minuscula\n",
        "    lowers = text.lower()\n",
        "    \n",
        "    # Quitar puntuación\n",
        "    no_punctuation = lowers.translate({ord(c): None for c in string.punctuation})\n",
        "    \n",
        "    # Tokenizar \n",
        "    tokens = nltk.word_tokenize(no_punctuation)\n",
        "    \n",
        "    # Retornar resultado\n",
        "    return tokens\n",
        "\n",
        "\n",
        "print(get_tokens(\"I'm a super student for recommender systems!\"))\n",
        "print(get_tokens(\"First sentence. Seconde sentence.\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['im', 'a', 'super', 'student', 'for', 'recommender', 'systems']\n",
            "['first', 'sentence', 'seconde', 'sentence']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckrxbKlTUVJ8",
        "colab_type": "text"
      },
      "source": [
        "En el código anterior, para ejecutar `nltk.word_tokenize()` era necesario tener descargado _punkt_. \n",
        "\n",
        "## Actividad 2\n",
        "\n",
        "En función a las frases ingresadas y al resultado impreso, ¿Qué significa _Tokenizar_?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpFOeSpET3BL",
        "colab_type": "text"
      },
      "source": [
        "**Respuesta:** COMPLETAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gifqhG3_ZO0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c7b8a5c7-489c-49ee-afd7-4f31c8fdebc0"
      },
      "source": [
        "# A cada abstract le aplicamos la función de get_tokens\n",
        "corpus_df['tokenized_abstract'] = corpus_df.abstract.map(get_tokens)\n",
        "corpus_df.head(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>Nonlinear Shape Statistics in Mumford{Shah Bas...</td>\n",
              "      <td>We present a variational integration of nonlin...</td>\n",
              "      <td>[we, present, a, variational, integration, of,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100007</td>\n",
              "      <td>On the Complexity of Equilibria</td>\n",
              "      <td>We prove complexity, approximability, and inap...</td>\n",
              "      <td>[we, prove, complexity, approximability, and, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100008</td>\n",
              "      <td>On QoS-Aware Publish-Subscribe</td>\n",
              "      <td>This position paper addresses the issue of sup...</td>\n",
              "      <td>[this, position, paper, addresses, the, issue,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001</td>\n",
              "      <td>Checking Mergeable Priority Queues</td>\n",
              "      <td>We present an efficient algorithm which can ch...</td>\n",
              "      <td>[we, present, an, efficient, algorithm, which,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100012</td>\n",
              "      <td>Mobile Code Security by Java Bytecode Instrume...</td>\n",
              "      <td>Mobile code provides significant opportunities...</td>\n",
              "      <td>[mobile, code, provides, significant, opportun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                              title  \\\n",
              "0  100002  Nonlinear Shape Statistics in Mumford{Shah Bas...   \n",
              "1  100007                    On the Complexity of Equilibria   \n",
              "2  100008                     On QoS-Aware Publish-Subscribe   \n",
              "3   10001                 Checking Mergeable Priority Queues   \n",
              "4  100012  Mobile Code Security by Java Bytecode Instrume...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  We present a variational integration of nonlin...   \n",
              "1  We prove complexity, approximability, and inap...   \n",
              "2  This position paper addresses the issue of sup...   \n",
              "3  We present an efficient algorithm which can ch...   \n",
              "4  Mobile code provides significant opportunities...   \n",
              "\n",
              "                                  tokenized_abstract  \n",
              "0  [we, present, a, variational, integration, of,...  \n",
              "1  [we, prove, complexity, approximability, and, ...  \n",
              "2  [this, position, paper, addresses, the, issue,...  \n",
              "3  [we, present, an, efficient, algorithm, which,...  \n",
              "4  [mobile, code, provides, significant, opportun...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkraQ1AwWT86",
        "colab_type": "text"
      },
      "source": [
        "Ahora se tiene que generar un diccionario con todas las palabras del *corpus*. Se recomienda revisar la documentación de gensim y leer cómo usar los diccionarios: [corpora.dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29j2p32oTTzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_file = './resources/dictionary.p'\n",
        "\n",
        "if isfile(dict_file): # Verificar si existe el archivo\n",
        "    dictionary = corpora.dictionary.Dictionary().load(dict_file)\n",
        "    \n",
        "else: # En otro caso, crear el archivo y guardarlo\n",
        "    dictionary = corpora.dictionary.Dictionary(documents=corpus_df.tokenised_abstract.tolist())\n",
        "    dictionary.save(dict_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEDzoAtbZdO1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "85c63021-8870-4b3f-c523-dae637193fdd"
      },
      "source": [
        "# Texto original\n",
        "print(\"Texto 1\")\n",
        "wrap(str(corpus_df.loc[0][\"tokenized_abstract\"]))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"['we', 'present', 'a', 'variational', 'integration', 'of',\",\n",
              " \"'nonlinear', 'shape', 'statistics', 'into', 'a', 'mumfordshah',\",\n",
              " \"'based', 'segmentation', 'process', 'the', 'nonlinear', 'statistics',\",\n",
              " \"'are', 'derived', 'from', 'a', 'set', 'of', 'training', 'silhouettes',\",\n",
              " \"'by', 'a', 'novel', 'method', 'of', 'density', 'estimation', 'which',\",\n",
              " \"'can', 'be', 'considered', 'as', 'an', 'extension', 'of', 'kernel',\",\n",
              " \"'pca', 'to', 'a', 'stochastic', 'framework']\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDJuYbHuY2rX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "644c5d1c-0a89-4e4b-f200-03814ef26b12"
      },
      "source": [
        "# Texto pasado por el diccionario\n",
        "print(\"Texto 1\")\n",
        "wrap(str(dictionary.doc2bow(corpus_df.loc[0][\"tokenized_abstract\"])))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9,',\n",
              " '1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (16, 1), (17, 1),',\n",
              " '(18, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26,',\n",
              " '2), (27, 1), (28, 1), (29, 1), (30, 5), (31, 1), (32, 1), (33, 1),',\n",
              " '(34, 1), (35, 4), (36, 1), (37, 1), (38, 1), (40, 1)]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Tbu3OUZ_qo",
        "colab_type": "text"
      },
      "source": [
        "Cuando se hizo `dictionary.doc2bow` se transformó una lista de palabas a un contador de ellas. En donde cada tupla representa `(ID, cantidad de veces)` de modo que se reduce la cantidad de palabras del texto a información numerica. \n",
        "\n",
        "Por ejemplo, la tupla `(30, 5)` indica que la palabra con ID 30 está 5 veces en el texto. Revisando el texto podemos ver que la palabra **\"a\"** es la que está repetida 5 veces. Esto implica que **\"a\"** está asignada al ID 30.\n",
        "\n",
        "Ahora aplicaremos esta función a cada texto del _dataset_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvEkoc9_ZsLy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6c4dea4d-e246-4d64-ec92-5eeca0cafc8e"
      },
      "source": [
        "corpus_df['bow'] = corpus_df.tokenized_abstract.map(dictionary.doc2bow)\n",
        "\n",
        "corpus = corpus_df['bow'].tolist()\n",
        "\n",
        "corpus_df.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "      <th>bow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>Nonlinear Shape Statistics in Mumford{Shah Bas...</td>\n",
              "      <td>We present a variational integration of nonlin...</td>\n",
              "      <td>[we, present, a, variational, integration, of,...</td>\n",
              "      <td>[(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100007</td>\n",
              "      <td>On the Complexity of Equilibria</td>\n",
              "      <td>We prove complexity, approximability, and inap...</td>\n",
              "      <td>[we, prove, complexity, approximability, and, ...</td>\n",
              "      <td>[(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100008</td>\n",
              "      <td>On QoS-Aware Publish-Subscribe</td>\n",
              "      <td>This position paper addresses the issue of sup...</td>\n",
              "      <td>[this, position, paper, addresses, the, issue,...</td>\n",
              "      <td>[(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001</td>\n",
              "      <td>Checking Mergeable Priority Queues</td>\n",
              "      <td>We present an efficient algorithm which can ch...</td>\n",
              "      <td>[we, present, an, efficient, algorithm, which,...</td>\n",
              "      <td>[(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100012</td>\n",
              "      <td>Mobile Code Security by Java Bytecode Instrume...</td>\n",
              "      <td>Mobile code provides significant opportunities...</td>\n",
              "      <td>[mobile, code, provides, significant, opportun...</td>\n",
              "      <td>[(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                              title  \\\n",
              "0  100002  Nonlinear Shape Statistics in Mumford{Shah Bas...   \n",
              "1  100007                    On the Complexity of Equilibria   \n",
              "2  100008                     On QoS-Aware Publish-Subscribe   \n",
              "3   10001                 Checking Mergeable Priority Queues   \n",
              "4  100012  Mobile Code Security by Java Bytecode Instrume...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  We present a variational integration of nonlin...   \n",
              "1  We prove complexity, approximability, and inap...   \n",
              "2  This position paper addresses the issue of sup...   \n",
              "3  We present an efficient algorithm which can ch...   \n",
              "4  Mobile code provides significant opportunities...   \n",
              "\n",
              "                                  tokenized_abstract  \\\n",
              "0  [we, present, a, variational, integration, of,...   \n",
              "1  [we, prove, complexity, approximability, and, ...   \n",
              "2  [this, position, paper, addresses, the, issue,...   \n",
              "3  [we, present, an, efficient, algorithm, which,...   \n",
              "4  [mobile, code, provides, significant, opportun...   \n",
              "\n",
              "                                                 bow  \n",
              "0  [(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...  \n",
              "1  [(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...  \n",
              "2  [(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...  \n",
              "3  [(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...  \n",
              "4  [(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f23GriULTHgV",
        "colab_type": "text"
      },
      "source": [
        "# Tf-idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQqcAAVrfwZw",
        "colab_type": "text"
      },
      "source": [
        "Recordemos que Tf-idf es una medida numérica que expresa cuán relevante es una palabra para un documento en una colección. Ahora, dada la frecuencia de cada palabra en cada texto, se v a utilizar esta ténica para obtener tuplas de la forma `(ID, Tf-idf)` en donde ID será el ID de la palabra igual como estaba antes (por ejemplo **\"a\"** tiene ID 30) y Tf-Idf será el valor dado por este algoritmo a la palabra en cuestión."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7ju5n3xTKtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "92bc965f-f7a8-40c4-aaa1-baea5fdb01bd"
      },
      "source": [
        "tfidf_model_file = 'resources/tfidf_model.p'\n",
        "\n",
        "if isfile(tfidf_model_file):\n",
        "    tfidf_model = models.tfidfmodel.TfidfModel().load(tfidf_model_file)\n",
        "\n",
        "else:\n",
        "    tfidf_model = models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary)\n",
        "    tfidf_model.save(tfidf_model_file)\n",
        "\n",
        "corpus_df['tf_idf'] = tfidf_model[corpus_df.bow.tolist()]\n",
        "corpus_df.head(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "      <th>bow</th>\n",
              "      <th>tf_idf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>Nonlinear Shape Statistics in Mumford{Shah Bas...</td>\n",
              "      <td>We present a variational integration of nonlin...</td>\n",
              "      <td>[we, present, a, variational, integration, of,...</td>\n",
              "      <td>[(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...</td>\n",
              "      <td>[(0, 0.19689725999527163), (1, 0.0861613877917...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100007</td>\n",
              "      <td>On the Complexity of Equilibria</td>\n",
              "      <td>We prove complexity, approximability, and inap...</td>\n",
              "      <td>[we, prove, complexity, approximability, and, ...</td>\n",
              "      <td>[(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...</td>\n",
              "      <td>[(4, 0.0033554011043417254), (7, 0.02333778550...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100008</td>\n",
              "      <td>On QoS-Aware Publish-Subscribe</td>\n",
              "      <td>This position paper addresses the issue of sup...</td>\n",
              "      <td>[this, position, paper, addresses, the, issue,...</td>\n",
              "      <td>[(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...</td>\n",
              "      <td>[(1, 0.06276351152911328), (4, 0.0049492930133...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001</td>\n",
              "      <td>Checking Mergeable Priority Queues</td>\n",
              "      <td>We present an efficient algorithm which can ch...</td>\n",
              "      <td>[we, present, an, efficient, algorithm, which,...</td>\n",
              "      <td>[(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...</td>\n",
              "      <td>[(4, 0.0022699486545179476), (7, 0.01127724975...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100012</td>\n",
              "      <td>Mobile Code Security by Java Bytecode Instrume...</td>\n",
              "      <td>Mobile code provides significant opportunities...</td>\n",
              "      <td>[mobile, code, provides, significant, opportun...</td>\n",
              "      <td>[(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...</td>\n",
              "      <td>[(4, 0.001715799318906219), (5, 0.031751265629...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                              title  \\\n",
              "0  100002  Nonlinear Shape Statistics in Mumford{Shah Bas...   \n",
              "1  100007                    On the Complexity of Equilibria   \n",
              "2  100008                     On QoS-Aware Publish-Subscribe   \n",
              "3   10001                 Checking Mergeable Priority Queues   \n",
              "4  100012  Mobile Code Security by Java Bytecode Instrume...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  We present a variational integration of nonlin...   \n",
              "1  We prove complexity, approximability, and inap...   \n",
              "2  This position paper addresses the issue of sup...   \n",
              "3  We present an efficient algorithm which can ch...   \n",
              "4  Mobile code provides significant opportunities...   \n",
              "\n",
              "                                  tokenized_abstract  \\\n",
              "0  [we, present, a, variational, integration, of,...   \n",
              "1  [we, prove, complexity, approximability, and, ...   \n",
              "2  [this, position, paper, addresses, the, issue,...   \n",
              "3  [we, present, an, efficient, algorithm, which,...   \n",
              "4  [mobile, code, provides, significant, opportun...   \n",
              "\n",
              "                                                 bow  \\\n",
              "0  [(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...   \n",
              "1  [(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...   \n",
              "2  [(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...   \n",
              "3  [(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...   \n",
              "4  [(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...   \n",
              "\n",
              "                                              tf_idf  \n",
              "0  [(0, 0.19689725999527163), (1, 0.0861613877917...  \n",
              "1  [(4, 0.0033554011043417254), (7, 0.02333778550...  \n",
              "2  [(1, 0.06276351152911328), (4, 0.0049492930133...  \n",
              "3  [(4, 0.0022699486545179476), (7, 0.01127724975...  \n",
              "4  [(4, 0.001715799318906219), (5, 0.031751265629...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU39mygGW8P9",
        "colab_type": "text"
      },
      "source": [
        "## Generar recomendaciones: \n",
        "En esta sección se implementan las funciones necesarias para poder generar recomendaciones dado lo que un usuario ha consumido. De manera artificial, se \"samplearán\" 3 documentos aleatorios que representarán al usuario objetivo (`sample`). Luego tendrás que generar diferentes recomendaciones y evaluar los resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzolZRLmWnOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "ad4770ba-5a99-4192-f793-f188db92d8d1"
      },
      "source": [
        "# Random users\n",
        "samples = corpus_df.sample(3)\n",
        "samples_ids = []\n",
        "\n",
        "for n, (ix, paper) in enumerate(samples.iterrows()):\n",
        "    samples_ids.append(ix)\n",
        "    idx, title, abstract, bow, tf_idf = paper[[\n",
        "        'id', 'title', 'abstract', 'bow', 'tf_idf']]\n",
        "    print('%d) %s' % (n+1, title))\n",
        "    print('')\n",
        "    print(\"\\n\".join(wrap(abstract)))\n",
        "    print('\\n')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1) On the (un)reality of Virtual Types\n",
            "\n",
            "We show, mostly through detailed examples, that programming patterns\n",
            "known to involve the notion of virtual types can be implemented\n",
            "directly and concisely using parametric polymorphism. A significant\n",
            "improvement we make over previous approaches is to allow related\n",
            "classes to be defined independently. This solution is more flexible,\n",
            "more general, and we believe, simpler than other type-safe solutions\n",
            "previously proposed. This approach can be applied to several languages\n",
            "with parametric polymorphism that can already type binary methods and\n",
            "have structural object types. We conclude that parametric polymorphism\n",
            "is always better than virtual types. Moreover, it avoids the\n",
            "introduction of a new non-atomic primitive construct. Introduction The\n",
            "programming patterns that lead to the introduction of virtual types\n",
            "are not new in the object-oriented community. However, they recently\n",
            "became famous for the typechecking challenges that they posed to some\n",
            "recent, modern, and statically typed object-...\n",
            "\n",
            "\n",
            "2) Feudal Reinforcement Learning\n",
            "\n",
            "One way to speed up reinforcement learning is to enable learning to\n",
            "happen simultaneously at multiple resolutions in space and time. This\n",
            "paper shows how to create a Q-learning managerial hierarchy in which\n",
            "high level managers learn how to set tasks to their sub-managers who,\n",
            "in turn, learn how to satisfy them. Sub-managers need not initially\n",
            "understand their managers' commands. They simply learn to maximise\n",
            "their reinforcement in the context of the current command. We\n",
            "illustrate the system using a simple maze task.. As the system learns\n",
            "how to get around, satisfying commands at the multiple levels, it\n",
            "explores more efficiently than standard, flat, Q-learning and builds a\n",
            "more comprehensive map. 1 INTRODUCTION Straightforward reinforcement\n",
            "learning has been quite successful at some relatively complex tasks\n",
            "like playing backgammon (Tesauro, 1992). However, the learning time\n",
            "does not scale well with the number of parameters. For agents solving\n",
            "rewarded Markovian decision tas...\n",
            "\n",
            "\n",
            "3) Affective Computing\n",
            "\n",
            "Recent neurological studies indicate that the role of emotion in human\n",
            "cognition is essential\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOgxiXx2XIkn",
        "colab_type": "text"
      },
      "source": [
        "Lo anterior son 3 textos tomados al azar. Asumiremso que una persona vió estos 3 textos y ahora vamos a recomendarle 5 nuevos por cada documento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et3iltfFWnW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recommendation functions\n",
        "\n",
        "N = len(dictionary)\n",
        "\n",
        "\n",
        "def to_sparse(matrix):\n",
        "    return csr_matrix([\n",
        "        gensim.matutils.sparse2full(row, length=N)\n",
        "        for row in matrix\n",
        "    ])\n",
        "\n",
        "\n",
        "def make_recommendations(model, metric, neighbors):\n",
        "    M = len(corpus)\n",
        "\n",
        "    X = to_sparse(corpus_df[model].tolist())\n",
        "    document_index = NearestNeighbors(\n",
        "        n_neighbors=(neighbors + 1),\n",
        "        algorithm='brute',\n",
        "        metric=metric).fit(X)\n",
        "    return document_index\n",
        "\n",
        "\n",
        "def print_recommendations(indexes, model):\n",
        "    for n, (ix, paper) in enumerate(samples.iterrows()):\n",
        "        dists, neighbors = indexes.kneighbors([gensim.matutils.sparse2full(paper[model], length=N)])\n",
        "        print(paper['title'])\n",
        "        print('')\n",
        "        print('Documentos cercanos: ')\n",
        "        i = 1\n",
        "        for neighbour in neighbors[0]:\n",
        "            if ix != neighbour:\n",
        "                line = str(i) + \". \" + corpus_df.iloc[neighbour]['title']\n",
        "                print(line)\n",
        "                i += 1\n",
        "        print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmgISQfTXNXB",
        "colab_type": "text"
      },
      "source": [
        "A continuación deberá utilizar las funciones implementadas anteriormente para generar nuevas recomendaciones variando los parámetros del modelo. **Agregue nuevas celdas para cada implementación y/o pregunta.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI9OZ52IWndk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "acd418d2-b83f-40fd-efb3-5262c69572d6"
      },
      "source": [
        "# Recommendation example: TF-IDF\n",
        "doc_idx = make_recommendations('tf_idf', 'euclidean', 5)\n",
        "print_recommendations(doc_idx, 'tf_idf')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On the (un)reality of Virtual Types\n",
            "\n",
            "Documentos cercanos: \n",
            "1. A Statically Safe Alternative to Virtual Types\n",
            "2. Lightweight Parametric Polymorphism for Oberon\n",
            "3. How to Make Ad-Hoc Polymorphism Less Ad Hoc\n",
            "4. Notes on Sconing and Relators\n",
            "5. The Cartesian Product Algorithm - Simple and Precise Type Inference of Parametric Polymorphism\n",
            "\n",
            "\n",
            "Feudal Reinforcement Learning\n",
            "\n",
            "Documentos cercanos: \n",
            "1. On-Line Q-Learning Using Connectionist Systems\n",
            "2. Context-Based Policy Search: Transfer of Experience Across Problems\n",
            "3. Hierarchical Learning in Stochastic Domains: Preliminary Results\n",
            "4. Learning Control Composition in a Complex Environment\n",
            "5. Problem Solving With Reinforcement Learning\n",
            "\n",
            "\n",
            "Affective Computing\n",
            "\n",
            "Documentos cercanos: \n",
            "1. Building Emotional Agents\n",
            "2. Toward Agents that Recognize Emotion\n",
            "3. Comprehension Processes During Large Scale Maintenance\n",
            "4. Towards a Society of Affect-driven Agents\n",
            "5. System Design by Composing Structures of Interacting Objects\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfInn_xVSmZ6",
        "colab_type": "text"
      },
      "source": [
        "# Stop words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LgcEzIcxM4W",
        "colab_type": "text"
      },
      "source": [
        "A continuación, intentaremos mejorar los resultados obtenidos con LDA eliminando las *stopwords*. ¿Qué son las *stopwords*? Son palabras vacías, sin significado, que no aportan (de manera significativa) al sentido de una frase, como los artículos, pronombres, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNlhgqHaVZuE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2425ad9a-8232-4519-80f4-4e7301dffef4"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTKiDBwpoJ4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    filtered_words = [\n",
        "        word for word in text if word not in stopwords.words('english')\n",
        "    ]\n",
        "    return filtered_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQFhKTk1xM4p",
        "colab_type": "text"
      },
      "source": [
        "Ahora eliminamos los stopwords de los textos y volvemos a hacer todo el proceso pero con textos diferentes. Este proceso dura aproximadamente **5 minutos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqQRTEtiUf1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a5a435bf-75b0-48d7-8a45-06542820252c"
      },
      "source": [
        "%%time\n",
        "# Puede que se demore un poco esta celda\n",
        "corpus_df['tokenized_abstract_without_stopwords'] = corpus_df.tokenized_abstract.map(remove_stopwords)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 43s, sys: 10.9 s, total: 1min 54s\n",
            "Wall time: 1min 54s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qf1SZ8DRQ6p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "39a3f731-f81e-4fb5-dac8-0a259d0ea68c"
      },
      "source": [
        "corpus_df.head(5)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "      <th>bow</th>\n",
              "      <th>tf_idf</th>\n",
              "      <th>tokenized_abstract_without_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>Nonlinear Shape Statistics in Mumford{Shah Bas...</td>\n",
              "      <td>We present a variational integration of nonlin...</td>\n",
              "      <td>[we, present, a, variational, integration, of,...</td>\n",
              "      <td>[(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...</td>\n",
              "      <td>[(0, 0.19689725999527163), (1, 0.0861613877917...</td>\n",
              "      <td>[present, variational, integration, nonlinear,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100007</td>\n",
              "      <td>On the Complexity of Equilibria</td>\n",
              "      <td>We prove complexity, approximability, and inap...</td>\n",
              "      <td>[we, prove, complexity, approximability, and, ...</td>\n",
              "      <td>[(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...</td>\n",
              "      <td>[(4, 0.0033554011043417254), (7, 0.02333778550...</td>\n",
              "      <td>[prove, complexity, approximability, inapproxi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100008</td>\n",
              "      <td>On QoS-Aware Publish-Subscribe</td>\n",
              "      <td>This position paper addresses the issue of sup...</td>\n",
              "      <td>[this, position, paper, addresses, the, issue,...</td>\n",
              "      <td>[(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...</td>\n",
              "      <td>[(1, 0.06276351152911328), (4, 0.0049492930133...</td>\n",
              "      <td>[position, paper, addresses, issue, supporting...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001</td>\n",
              "      <td>Checking Mergeable Priority Queues</td>\n",
              "      <td>We present an efficient algorithm which can ch...</td>\n",
              "      <td>[we, present, an, efficient, algorithm, which,...</td>\n",
              "      <td>[(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...</td>\n",
              "      <td>[(4, 0.0022699486545179476), (7, 0.01127724975...</td>\n",
              "      <td>[present, efficient, algorithm, check, answers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100012</td>\n",
              "      <td>Mobile Code Security by Java Bytecode Instrume...</td>\n",
              "      <td>Mobile code provides significant opportunities...</td>\n",
              "      <td>[mobile, code, provides, significant, opportun...</td>\n",
              "      <td>[(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...</td>\n",
              "      <td>[(4, 0.001715799318906219), (5, 0.031751265629...</td>\n",
              "      <td>[mobile, code, provides, significant, opportun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                              title  \\\n",
              "0  100002  Nonlinear Shape Statistics in Mumford{Shah Bas...   \n",
              "1  100007                    On the Complexity of Equilibria   \n",
              "2  100008                     On QoS-Aware Publish-Subscribe   \n",
              "3   10001                 Checking Mergeable Priority Queues   \n",
              "4  100012  Mobile Code Security by Java Bytecode Instrume...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  We present a variational integration of nonlin...   \n",
              "1  We prove complexity, approximability, and inap...   \n",
              "2  This position paper addresses the issue of sup...   \n",
              "3  We present an efficient algorithm which can ch...   \n",
              "4  Mobile code provides significant opportunities...   \n",
              "\n",
              "                                  tokenized_abstract  \\\n",
              "0  [we, present, a, variational, integration, of,...   \n",
              "1  [we, prove, complexity, approximability, and, ...   \n",
              "2  [this, position, paper, addresses, the, issue,...   \n",
              "3  [we, present, an, efficient, algorithm, which,...   \n",
              "4  [mobile, code, provides, significant, opportun...   \n",
              "\n",
              "                                                 bow  \\\n",
              "0  [(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...   \n",
              "1  [(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...   \n",
              "2  [(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...   \n",
              "3  [(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...   \n",
              "4  [(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...   \n",
              "\n",
              "                                              tf_idf  \\\n",
              "0  [(0, 0.19689725999527163), (1, 0.0861613877917...   \n",
              "1  [(4, 0.0033554011043417254), (7, 0.02333778550...   \n",
              "2  [(1, 0.06276351152911328), (4, 0.0049492930133...   \n",
              "3  [(4, 0.0022699486545179476), (7, 0.01127724975...   \n",
              "4  [(4, 0.001715799318906219), (5, 0.031751265629...   \n",
              "\n",
              "                tokenized_abstract_without_stopwords  \n",
              "0  [present, variational, integration, nonlinear,...  \n",
              "1  [prove, complexity, approximability, inapproxi...  \n",
              "2  [position, paper, addresses, issue, supporting...  \n",
              "3  [present, efficient, algorithm, check, answers...  \n",
              "4  [mobile, code, provides, significant, opportun...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsAcYiECX0FO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "c108b108-74a4-44c4-9d59-ee2e9494d856"
      },
      "source": [
        "corpus_df['bow_without_stopwords'] = corpus_df.tokenized_abstract_without_stopwords.map(dictionary.doc2bow)\n",
        "corpus_df.head(5)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "      <th>bow</th>\n",
              "      <th>tf_idf</th>\n",
              "      <th>tokenized_abstract_without_stopwords</th>\n",
              "      <th>bow_without_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>Nonlinear Shape Statistics in Mumford{Shah Bas...</td>\n",
              "      <td>We present a variational integration of nonlin...</td>\n",
              "      <td>[we, present, a, variational, integration, of,...</td>\n",
              "      <td>[(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...</td>\n",
              "      <td>[(0, 0.19689725999527163), (1, 0.0861613877917...</td>\n",
              "      <td>[present, variational, integration, nonlinear,...</td>\n",
              "      <td>[(0, 1), (1, 1), (3, 1), (6, 1), (9, 1), (11, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100007</td>\n",
              "      <td>On the Complexity of Equilibria</td>\n",
              "      <td>We prove complexity, approximability, and inap...</td>\n",
              "      <td>[we, prove, complexity, approximability, and, ...</td>\n",
              "      <td>[(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...</td>\n",
              "      <td>[(4, 0.0033554011043417254), (7, 0.02333778550...</td>\n",
              "      <td>[prove, complexity, approximability, inapproxi...</td>\n",
              "      <td>[(42, 1), (43, 1), (44, 1), (45, 1), (46, 1), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100008</td>\n",
              "      <td>On QoS-Aware Publish-Subscribe</td>\n",
              "      <td>This position paper addresses the issue of sup...</td>\n",
              "      <td>[this, position, paper, addresses, the, issue,...</td>\n",
              "      <td>[(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...</td>\n",
              "      <td>[(1, 0.06276351152911328), (4, 0.0049492930133...</td>\n",
              "      <td>[position, paper, addresses, issue, supporting...</td>\n",
              "      <td>[(1, 1), (90, 1), (91, 3), (92, 1), (93, 1), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001</td>\n",
              "      <td>Checking Mergeable Priority Queues</td>\n",
              "      <td>We present an efficient algorithm which can ch...</td>\n",
              "      <td>[we, present, an, efficient, algorithm, which,...</td>\n",
              "      <td>[(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...</td>\n",
              "      <td>[(4, 0.0022699486545179476), (7, 0.01127724975...</td>\n",
              "      <td>[present, efficient, algorithm, check, answers...</td>\n",
              "      <td>[(29, 1), (85, 2), (95, 1), (133, 1), (134, 1)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100012</td>\n",
              "      <td>Mobile Code Security by Java Bytecode Instrume...</td>\n",
              "      <td>Mobile code provides significant opportunities...</td>\n",
              "      <td>[mobile, code, provides, significant, opportun...</td>\n",
              "      <td>[(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...</td>\n",
              "      <td>[(4, 0.001715799318906219), (5, 0.031751265629...</td>\n",
              "      <td>[mobile, code, provides, significant, opportun...</td>\n",
              "      <td>[(25, 1), (29, 1), (103, 1), (108, 1), (172, 3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                              title  \\\n",
              "0  100002  Nonlinear Shape Statistics in Mumford{Shah Bas...   \n",
              "1  100007                    On the Complexity of Equilibria   \n",
              "2  100008                     On QoS-Aware Publish-Subscribe   \n",
              "3   10001                 Checking Mergeable Priority Queues   \n",
              "4  100012  Mobile Code Security by Java Bytecode Instrume...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  We present a variational integration of nonlin...   \n",
              "1  We prove complexity, approximability, and inap...   \n",
              "2  This position paper addresses the issue of sup...   \n",
              "3  We present an efficient algorithm which can ch...   \n",
              "4  Mobile code provides significant opportunities...   \n",
              "\n",
              "                                  tokenized_abstract  \\\n",
              "0  [we, present, a, variational, integration, of,...   \n",
              "1  [we, prove, complexity, approximability, and, ...   \n",
              "2  [this, position, paper, addresses, the, issue,...   \n",
              "3  [we, present, an, efficient, algorithm, which,...   \n",
              "4  [mobile, code, provides, significant, opportun...   \n",
              "\n",
              "                                                 bow  \\\n",
              "0  [(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...   \n",
              "1  [(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...   \n",
              "2  [(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...   \n",
              "3  [(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...   \n",
              "4  [(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...   \n",
              "\n",
              "                                              tf_idf  \\\n",
              "0  [(0, 0.19689725999527163), (1, 0.0861613877917...   \n",
              "1  [(4, 0.0033554011043417254), (7, 0.02333778550...   \n",
              "2  [(1, 0.06276351152911328), (4, 0.0049492930133...   \n",
              "3  [(4, 0.0022699486545179476), (7, 0.01127724975...   \n",
              "4  [(4, 0.001715799318906219), (5, 0.031751265629...   \n",
              "\n",
              "                tokenized_abstract_without_stopwords  \\\n",
              "0  [present, variational, integration, nonlinear,...   \n",
              "1  [prove, complexity, approximability, inapproxi...   \n",
              "2  [position, paper, addresses, issue, supporting...   \n",
              "3  [present, efficient, algorithm, check, answers...   \n",
              "4  [mobile, code, provides, significant, opportun...   \n",
              "\n",
              "                               bow_without_stopwords  \n",
              "0  [(0, 1), (1, 1), (3, 1), (6, 1), (9, 1), (11, ...  \n",
              "1  [(42, 1), (43, 1), (44, 1), (45, 1), (46, 1), ...  \n",
              "2  [(1, 1), (90, 1), (91, 3), (92, 1), (93, 1), (...  \n",
              "3  [(29, 1), (85, 2), (95, 1), (133, 1), (134, 1)...  \n",
              "4  [(25, 1), (29, 1), (103, 1), (108, 1), (172, 3...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2CWQqabaUFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4e569d2-cc3e-48ec-fad5-036c03f08867"
      },
      "source": [
        "corpus = corpus_df['bow_without_stopwords'].tolist()\n",
        "\n",
        "tfidf_model_file_without_stopwords = 'resources/tfidf_model.p'\n",
        "\n",
        "if isfile(tfidf_model_file):\n",
        "    tfidf_model_without_stopwords = models.tfidfmodel.TfidfModel().load(tfidf_model_file)\n",
        "\n",
        "else:\n",
        "    tfidf_model_without_stopwords = models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary)\n",
        "    tfidf_model_without_stopwords.save(tfidf_model_file_without_stopwords)\n",
        "\n",
        "corpus_df['tf_idf_without_stopwords'] = tfidf_model_without_stopwords[corpus_df.bow_without_stopwords.tolist()]\n",
        "corpus_df.head(5)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "      <th>bow</th>\n",
              "      <th>tf_idf</th>\n",
              "      <th>tokenized_abstract_without_stopwords</th>\n",
              "      <th>bow_without_stopwords</th>\n",
              "      <th>tf_idf_without_stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>Nonlinear Shape Statistics in Mumford{Shah Bas...</td>\n",
              "      <td>We present a variational integration of nonlin...</td>\n",
              "      <td>[we, present, a, variational, integration, of,...</td>\n",
              "      <td>[(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...</td>\n",
              "      <td>[(0, 0.19689725999527163), (1, 0.0861613877917...</td>\n",
              "      <td>[present, variational, integration, nonlinear,...</td>\n",
              "      <td>[(0, 1), (1, 1), (3, 1), (6, 1), (9, 1), (11, ...</td>\n",
              "      <td>[(0, 0.19859067348407708), (1, 0.0869024181966...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100007</td>\n",
              "      <td>On the Complexity of Equilibria</td>\n",
              "      <td>We prove complexity, approximability, and inap...</td>\n",
              "      <td>[we, prove, complexity, approximability, and, ...</td>\n",
              "      <td>[(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...</td>\n",
              "      <td>[(4, 0.0033554011043417254), (7, 0.02333778550...</td>\n",
              "      <td>[prove, complexity, approximability, inapproxi...</td>\n",
              "      <td>[(42, 1), (43, 1), (44, 1), (45, 1), (46, 1), ...</td>\n",
              "      <td>[(42, 0.1372259998572753), (43, 0.045914969188...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100008</td>\n",
              "      <td>On QoS-Aware Publish-Subscribe</td>\n",
              "      <td>This position paper addresses the issue of sup...</td>\n",
              "      <td>[this, position, paper, addresses, the, issue,...</td>\n",
              "      <td>[(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...</td>\n",
              "      <td>[(1, 0.06276351152911328), (4, 0.0049492930133...</td>\n",
              "      <td>[position, paper, addresses, issue, supporting...</td>\n",
              "      <td>[(1, 1), (90, 1), (91, 3), (92, 1), (93, 1), (...</td>\n",
              "      <td>[(1, 0.06604705077143881), (90, 0.172432977199...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001</td>\n",
              "      <td>Checking Mergeable Priority Queues</td>\n",
              "      <td>We present an efficient algorithm which can ch...</td>\n",
              "      <td>[we, present, an, efficient, algorithm, which,...</td>\n",
              "      <td>[(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...</td>\n",
              "      <td>[(4, 0.0022699486545179476), (7, 0.01127724975...</td>\n",
              "      <td>[present, efficient, algorithm, check, answers...</td>\n",
              "      <td>[(29, 1), (85, 2), (95, 1), (133, 1), (134, 1)...</td>\n",
              "      <td>[(29, 0.020859058995752067), (85, 0.0447629771...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100012</td>\n",
              "      <td>Mobile Code Security by Java Bytecode Instrume...</td>\n",
              "      <td>Mobile code provides significant opportunities...</td>\n",
              "      <td>[mobile, code, provides, significant, opportun...</td>\n",
              "      <td>[(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...</td>\n",
              "      <td>[(4, 0.001715799318906219), (5, 0.031751265629...</td>\n",
              "      <td>[mobile, code, provides, significant, opportun...</td>\n",
              "      <td>[(25, 1), (29, 1), (103, 1), (108, 1), (172, 3...</td>\n",
              "      <td>[(25, 0.04074940143660829), (29, 0.02767893128...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                              title  \\\n",
              "0  100002  Nonlinear Shape Statistics in Mumford{Shah Bas...   \n",
              "1  100007                    On the Complexity of Equilibria   \n",
              "2  100008                     On QoS-Aware Publish-Subscribe   \n",
              "3   10001                 Checking Mergeable Priority Queues   \n",
              "4  100012  Mobile Code Security by Java Bytecode Instrume...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  We present a variational integration of nonlin...   \n",
              "1  We prove complexity, approximability, and inap...   \n",
              "2  This position paper addresses the issue of sup...   \n",
              "3  We present an efficient algorithm which can ch...   \n",
              "4  Mobile code provides significant opportunities...   \n",
              "\n",
              "                                  tokenized_abstract  \\\n",
              "0  [we, present, a, variational, integration, of,...   \n",
              "1  [we, prove, complexity, approximability, and, ...   \n",
              "2  [this, position, paper, addresses, the, issue,...   \n",
              "3  [we, present, an, efficient, algorithm, which,...   \n",
              "4  [mobile, code, provides, significant, opportun...   \n",
              "\n",
              "                                                 bow  \\\n",
              "0  [(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...   \n",
              "1  [(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...   \n",
              "2  [(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...   \n",
              "3  [(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...   \n",
              "4  [(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...   \n",
              "\n",
              "                                              tf_idf  \\\n",
              "0  [(0, 0.19689725999527163), (1, 0.0861613877917...   \n",
              "1  [(4, 0.0033554011043417254), (7, 0.02333778550...   \n",
              "2  [(1, 0.06276351152911328), (4, 0.0049492930133...   \n",
              "3  [(4, 0.0022699486545179476), (7, 0.01127724975...   \n",
              "4  [(4, 0.001715799318906219), (5, 0.031751265629...   \n",
              "\n",
              "                tokenized_abstract_without_stopwords  \\\n",
              "0  [present, variational, integration, nonlinear,...   \n",
              "1  [prove, complexity, approximability, inapproxi...   \n",
              "2  [position, paper, addresses, issue, supporting...   \n",
              "3  [present, efficient, algorithm, check, answers...   \n",
              "4  [mobile, code, provides, significant, opportun...   \n",
              "\n",
              "                               bow_without_stopwords  \\\n",
              "0  [(0, 1), (1, 1), (3, 1), (6, 1), (9, 1), (11, ...   \n",
              "1  [(42, 1), (43, 1), (44, 1), (45, 1), (46, 1), ...   \n",
              "2  [(1, 1), (90, 1), (91, 3), (92, 1), (93, 1), (...   \n",
              "3  [(29, 1), (85, 2), (95, 1), (133, 1), (134, 1)...   \n",
              "4  [(25, 1), (29, 1), (103, 1), (108, 1), (172, 3...   \n",
              "\n",
              "                            tf_idf_without_stopwords  \n",
              "0  [(0, 0.19859067348407708), (1, 0.0869024181966...  \n",
              "1  [(42, 0.1372259998572753), (43, 0.045914969188...  \n",
              "2  [(1, 0.06604705077143881), (90, 0.172432977199...  \n",
              "3  [(29, 0.020859058995752067), (85, 0.0447629771...  \n",
              "4  [(25, 0.04074940143660829), (29, 0.02767893128...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxqEz_S0ensc",
        "colab_type": "text"
      },
      "source": [
        "# Word Embeddings\n",
        "En esta sección haremos recomendacion de textos médicos de [PubMed](https://www.ncbi.nlm.nih.gov/pubmed/) que han sido revisados por expertos. \n",
        "\n",
        "RESPONDER LAS SIGUIENTES PREGUNTAS: \n",
        "- ¿Que son word embeddings? ¿Cuál es la intuición?\n",
        "- ¿Por qué son útiles para representar documentos?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vnYP9TQSdfV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "20c1b06a-5194-4ad1-8306-062fea669832"
      },
      "source": [
        "# Descarga de recursos\n",
        "!wget https://www.dropbox.com/s/gc3x9rp4gu2tmch/documents_w2vec.json.zip\n",
        "!unzip documents_w2vec.json.zip"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-26 16:17:54--  https://www.dropbox.com/s/gc3x9rp4gu2tmch/documents_w2vec.json.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/gc3x9rp4gu2tmch/documents_w2vec.json.zip [following]\n",
            "--2019-08-26 16:17:55--  https://www.dropbox.com/s/raw/gc3x9rp4gu2tmch/documents_w2vec.json.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc2565c6c54653ef667fc2ef6a88.dl.dropboxusercontent.com/cd/0/inline/AnWilxwhQR7C_GiIUIXbD16kShnuXmhQaFzdLaGEx0mG4ILdJaXy_lq6mhVn4Rn4EL9GQYWtJ0jA8sk9Sds1tK29V_q79YfICRAYZ2HsXnzX9mIJC8KY0CRzwrBN4bd0uwU/file# [following]\n",
            "--2019-08-26 16:17:55--  https://uc2565c6c54653ef667fc2ef6a88.dl.dropboxusercontent.com/cd/0/inline/AnWilxwhQR7C_GiIUIXbD16kShnuXmhQaFzdLaGEx0mG4ILdJaXy_lq6mhVn4Rn4EL9GQYWtJ0jA8sk9Sds1tK29V_q79YfICRAYZ2HsXnzX9mIJC8KY0CRzwrBN4bd0uwU/file\n",
            "Resolving uc2565c6c54653ef667fc2ef6a88.dl.dropboxusercontent.com (uc2565c6c54653ef667fc2ef6a88.dl.dropboxusercontent.com)... 162.125.1.6, 2620:100:6016:6::a27d:106\n",
            "Connecting to uc2565c6c54653ef667fc2ef6a88.dl.dropboxusercontent.com (uc2565c6c54653ef667fc2ef6a88.dl.dropboxusercontent.com)|162.125.1.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AnWtVJpTtvdHHsCy5eqJNDtY7-u-znapk1SDPHf38YYoy7vX5YmLgqHfvdyQuumnjED3oRmn0mxDzIbpCAjknxkwTpxEXnkgVBVF_hdrCWzbgIbbW1DK_HgQUA1Y6DIzaPzRvV6CgjUC5V2NEcb54v9ZUbZG6AvlkXL1z7Ks7EubUW9x2wLOP3Xn6AkBvFhubPau1g6SV08NaOG6BHH85OCUhEt9Hz3VwElJjFsYUS3rOuukFQffz3yYh-EG6SlaopvI_O9umicqtaTjtqfEWXWU1FfTvBTb3N6t9F__GO-gD0vnBJAo7kSQuZEGhQa97RWV4a4TzfKESrCAoxFArXyfTaCxim5Kq6FQnRQAMybKEA/file [following]\n",
            "--2019-08-26 16:17:55--  https://uc2565c6c54653ef667fc2ef6a88.dl.dropboxusercontent.com/cd/0/inline2/AnWtVJpTtvdHHsCy5eqJNDtY7-u-znapk1SDPHf38YYoy7vX5YmLgqHfvdyQuumnjED3oRmn0mxDzIbpCAjknxkwTpxEXnkgVBVF_hdrCWzbgIbbW1DK_HgQUA1Y6DIzaPzRvV6CgjUC5V2NEcb54v9ZUbZG6AvlkXL1z7Ks7EubUW9x2wLOP3Xn6AkBvFhubPau1g6SV08NaOG6BHH85OCUhEt9Hz3VwElJjFsYUS3rOuukFQffz3yYh-EG6SlaopvI_O9umicqtaTjtqfEWXWU1FfTvBTb3N6t9F__GO-gD0vnBJAo7kSQuZEGhQa97RWV4a4TzfKESrCAoxFArXyfTaCxim5Kq6FQnRQAMybKEA/file\n",
            "Reusing existing connection to uc2565c6c54653ef667fc2ef6a88.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 533530982 (509M) [application/zip]\n",
            "Saving to: ‘documents_w2vec.json.zip’\n",
            "\n",
            "documents_w2vec.jso 100%[===================>] 508.81M  39.1MB/s    in 46s     \n",
            "\n",
            "2019-08-26 16:18:41 (11.2 MB/s) - ‘documents_w2vec.json.zip’ saved [533530982/533530982]\n",
            "\n",
            "Archive:  documents_w2vec.json.zip\n",
            "  inflating: documents_w2vec.json    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmyJj4cbSdnP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "324bc9fe-8f95-4737-906c-74a6dcf319e6"
      },
      "source": [
        "# Descarga del dataset\n",
        "!wget https://www.dropbox.com/s/1bxuw3uf3xwyrr7/pubmed_data.csv"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-26 16:18:57--  https://www.dropbox.com/s/1bxuw3uf3xwyrr7/pubmed_data.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/1bxuw3uf3xwyrr7/pubmed_data.csv [following]\n",
            "--2019-08-26 16:18:57--  https://www.dropbox.com/s/raw/1bxuw3uf3xwyrr7/pubmed_data.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc98f7795cfff123cca542a3088a.dl.dropboxusercontent.com/cd/0/inline/AnUHlhG_FV6Ff4MHTBcLMkjmzT19dh_1PyDa6hp05gBPF7cqwsyAYGqNll5Fh1Jh3A81IeB770ZOzkQZzgYeoq9EolgQAr4U_OZMxvNRinpbwLxuLqvn_Tx-kKShSURtg6k/file# [following]\n",
            "--2019-08-26 16:18:58--  https://uc98f7795cfff123cca542a3088a.dl.dropboxusercontent.com/cd/0/inline/AnUHlhG_FV6Ff4MHTBcLMkjmzT19dh_1PyDa6hp05gBPF7cqwsyAYGqNll5Fh1Jh3A81IeB770ZOzkQZzgYeoq9EolgQAr4U_OZMxvNRinpbwLxuLqvn_Tx-kKShSURtg6k/file\n",
            "Resolving uc98f7795cfff123cca542a3088a.dl.dropboxusercontent.com (uc98f7795cfff123cca542a3088a.dl.dropboxusercontent.com)... 162.125.1.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to uc98f7795cfff123cca542a3088a.dl.dropboxusercontent.com (uc98f7795cfff123cca542a3088a.dl.dropboxusercontent.com)|162.125.1.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 332929414 (318M) [text/plain]\n",
            "Saving to: ‘pubmed_data.csv’\n",
            "\n",
            "pubmed_data.csv     100%[===================>] 317.51M  56.3MB/s    in 16s     \n",
            "\n",
            "2019-08-26 16:19:14 (19.6 MB/s) - ‘pubmed_data.csv’ saved [332929414/332929414]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HY0AggcTvH0",
        "colab_type": "text"
      },
      "source": [
        "Podemos ver que este _dataet: contiene 4 columnas:\n",
        "* **user_id**: identificador de cada usuario \n",
        "* **pid**: identificador de cada texto con su correlativo de PubMed. \n",
        "* **_title_**: título del documento, en este caso, de un _paper_\n",
        "* **_abstract_**: primer párafo del _paper_ que es una representación abreviada, objetiva y precisa del contenido de un documento o recurso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dKbIzvXTr-N",
        "colab_type": "code",
        "outputId": "341b15e0-17b4-4bcb-df52-682bd176177f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv('pubmed_data.csv')\n",
        "df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>pid</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>348892</td>\n",
              "      <td>3242144</td>\n",
              "      <td>Value of percutaneous transhepatic cholangiosc...</td>\n",
              "      <td>Since July 1975, percutaneous transhepatic bil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>348893</td>\n",
              "      <td>3242144</td>\n",
              "      <td>Value of percutaneous transhepatic cholangiosc...</td>\n",
              "      <td>Since July 1975, percutaneous transhepatic bil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>348894</td>\n",
              "      <td>3242144</td>\n",
              "      <td>Value of percutaneous transhepatic cholangiosc...</td>\n",
              "      <td>Since July 1975, percutaneous transhepatic bil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>343531</td>\n",
              "      <td>17347632</td>\n",
              "      <td>Endoscopic management of a large choledochocel...</td>\n",
              "      <td>Choledochocele or type III choledochal cyst is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>348892</td>\n",
              "      <td>17347632</td>\n",
              "      <td>Endoscopic management of a large choledochocel...</td>\n",
              "      <td>Choledochocele or type III choledochal cyst is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id       pid                                              title  \\\n",
              "0   348892   3242144  Value of percutaneous transhepatic cholangiosc...   \n",
              "1   348893   3242144  Value of percutaneous transhepatic cholangiosc...   \n",
              "2   348894   3242144  Value of percutaneous transhepatic cholangiosc...   \n",
              "3   343531  17347632  Endoscopic management of a large choledochocel...   \n",
              "4   348892  17347632  Endoscopic management of a large choledochocel...   \n",
              "\n",
              "                                            abstract  \n",
              "0  Since July 1975, percutaneous transhepatic bil...  \n",
              "1  Since July 1975, percutaneous transhepatic bil...  \n",
              "2  Since July 1975, percutaneous transhepatic bil...  \n",
              "3  Choledochocele or type III choledochal cyst is...  \n",
              "4  Choledochocele or type III choledochal cyst is...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGXXyftCUAOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creamos diccionario de titulos y abstracts que utilizaremos despues\n",
        "dict_title_abstract = {}\n",
        "\n",
        "for pid, title, abstract in zip(df.pid, df.title, df.abstract):\n",
        "  dict_title_abstract[pid] = {'title': title, 'abstract': abstract}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE0JMfF4Sd3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cargamos diccionario de embeddings por cada documento (pre-procesado)\n",
        "w2vec_vectors = json.load(open('documents_w2vec.json'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqjurNgZVBHp",
        "colab_type": "text"
      },
      "source": [
        "creamos un objeto *gensim.keyedvectors* para hacer más eficiente la búsqueda de documentos similares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhKPIiaCU-5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size = 300\n",
        "\n",
        "doc2vec = gensim.models.keyedvectors.Word2VecKeyedVectors(embedding_size)\n",
        "keys = list(w2vec_vectors.keys())\n",
        "values = [\n",
        "    w2vec_vectors[key]\n",
        "    for key in keys\n",
        "]\n",
        "doc2vec.add(keys, values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74V5fvAfY3cQ",
        "colab_type": "text"
      },
      "source": [
        "## Generar recomendaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL7YfnQaUxge",
        "colab_type": "text"
      },
      "source": [
        "función **find_similar** para encontrar documentos similares a un pid en particular que recibe id del documento y los topn documentos mas similares y retorna topn documentos más similares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYpU31trUG6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_similar(pid, topn):\n",
        "  results = []\n",
        "\n",
        "  for id_, score in doc2vec.similar_by_vector(doc2vec[pid], topn=topn):\n",
        "      results.append([id_, score, dict_title_abstract[int(id_)]['title'], dict_title_abstract[int(id_)]['abstract']])\n",
        "\n",
        "  return pd.DataFrame(results[1:], columns = ['pid', 'score', 'title', 'abstract'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hdVsRKTUHCB",
        "colab_type": "code",
        "outputId": "eb2b62db-e660-4c19-96f0-e18e55f0729e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "find_similar('22508578', 10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pid</th>\n",
              "      <th>score</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19246909</td>\n",
              "      <td>0.893572</td>\n",
              "      <td>Validation study of the Mini-Mental State Exam...</td>\n",
              "      <td>In view of the differing sensitivity and speci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12211125</td>\n",
              "      <td>0.885023</td>\n",
              "      <td>The distribution of Mini-Mental State Examinat...</td>\n",
              "      <td>to describe normative data for the Mini-Mental...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1538203</td>\n",
              "      <td>0.880047</td>\n",
              "      <td>Statistical description of the Mini-Mental Sta...</td>\n",
              "      <td>The distribution of total Mini-Mental State Ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17221080</td>\n",
              "      <td>0.879309</td>\n",
              "      <td>Mini-Mental State Examination norms in a commu...</td>\n",
              "      <td>The objective of this study was to assess Mini...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19337986</td>\n",
              "      <td>0.876571</td>\n",
              "      <td>Reliability and validity of revised Turkish ve...</td>\n",
              "      <td>To evaluate the reliability and validity of th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>17936377</td>\n",
              "      <td>0.875227</td>\n",
              "      <td>An adaptation of the Korean mini-mental state ...</td>\n",
              "      <td>The mini-mental state examination (MMSE) is a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18983719</td>\n",
              "      <td>0.873318</td>\n",
              "      <td>Applicability of the Mini-mental State Examina...</td>\n",
              "      <td>The Mini-mental State Examination (MMSE) is a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>16906312</td>\n",
              "      <td>0.872315</td>\n",
              "      <td>[Mini-Mental State Examination: psychometric c...</td>\n",
              "      <td>To assess the psychometric characteristics of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1601631</td>\n",
              "      <td>0.866430</td>\n",
              "      <td>Mini-Mental State Examination (MMSE): sensitiv...</td>\n",
              "      <td>The sensitivity of the Mini-Mental State Exami...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        pid     score                                              title  \\\n",
              "0  19246909  0.893572  Validation study of the Mini-Mental State Exam...   \n",
              "1  12211125  0.885023  The distribution of Mini-Mental State Examinat...   \n",
              "2   1538203  0.880047  Statistical description of the Mini-Mental Sta...   \n",
              "3  17221080  0.879309  Mini-Mental State Examination norms in a commu...   \n",
              "4  19337986  0.876571  Reliability and validity of revised Turkish ve...   \n",
              "5  17936377  0.875227  An adaptation of the Korean mini-mental state ...   \n",
              "6  18983719  0.873318  Applicability of the Mini-mental State Examina...   \n",
              "7  16906312  0.872315  [Mini-Mental State Examination: psychometric c...   \n",
              "8   1601631  0.866430  Mini-Mental State Examination (MMSE): sensitiv...   \n",
              "\n",
              "                                            abstract  \n",
              "0  In view of the differing sensitivity and speci...  \n",
              "1  to describe normative data for the Mini-Mental...  \n",
              "2  The distribution of total Mini-Mental State Ex...  \n",
              "3  The objective of this study was to assess Mini...  \n",
              "4  To evaluate the reliability and validity of th...  \n",
              "5  The mini-mental state examination (MMSE) is a ...  \n",
              "6  The Mini-mental State Examination (MMSE) is a ...  \n",
              "7  To assess the psychometric characteristics of ...  \n",
              "8  The sensitivity of the Mini-Mental State Exami...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqovwUr7VNMx",
        "colab_type": "text"
      },
      "source": [
        "función **recommend** para recomendar a un usuario de acuerdo una muestra de documentos que ha leído."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl5-3vZCUHHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recommend(user_id, topn, sample_user):\n",
        "  user_docs =  df[df.user_id==user_id]['pid'].sample(sample_user)\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for pid in user_docs:\n",
        "\n",
        "    for id_, score in doc2vec.similar_by_vector(doc2vec[str(pid)], topn=topn):\n",
        "\n",
        "      if int(id_) in dict_title_abstract:\n",
        "        results.append([id_, score, dict_title_abstract[int(id_)]['title'], dict_title_abstract[int(id_)]['abstract']])\n",
        "    \n",
        "\n",
        "  results = sorted(results, key = lambda x: int(x[1]))\n",
        "\n",
        "  return pd.DataFrame(results[topn:], columns = ['pid', 'score', 'title', 'abstract']).head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN1yayQPUHKv",
        "colab_type": "code",
        "outputId": "7ea63885-b12f-4963-875b-4b4a6eb620a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# documentos leidos por el usuario \n",
        "df[df.user_id==348892].sample(10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>pid</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>175227</th>\n",
              "      <td>348892</td>\n",
              "      <td>1292768</td>\n",
              "      <td>[Percutaneous removal of residual calculi of t...</td>\n",
              "      <td>Percutaneous instrumentation under fluoroscopi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153482</th>\n",
              "      <td>348892</td>\n",
              "      <td>22104745</td>\n",
              "      <td>Update in biliary endoscopy.</td>\n",
              "      <td>Biliary endoscopy has seen the development of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2962</th>\n",
              "      <td>348892</td>\n",
              "      <td>9171132</td>\n",
              "      <td>Long-term results after laparoscopic cholecyst...</td>\n",
              "      <td>Cholecystotomy has been suggested for symptoma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247775</th>\n",
              "      <td>348892</td>\n",
              "      <td>16968186</td>\n",
              "      <td>Multilocular flank abscess due to stone migrat...</td>\n",
              "      <td>We report a case of a patient who presented wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4153</th>\n",
              "      <td>348892</td>\n",
              "      <td>22519190</td>\n",
              "      <td>Dietary habits as a risk factor of gallstone d...</td>\n",
              "      <td>Gallstone formation is a multifactorial diseas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174710</th>\n",
              "      <td>348892</td>\n",
              "      <td>1670228</td>\n",
              "      <td>Results of laparoscopic cholecystectomy in a u...</td>\n",
              "      <td>This study analyzed the first 100 laparoscopic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10031</th>\n",
              "      <td>348892</td>\n",
              "      <td>16391906</td>\n",
              "      <td>Pneumobilia: where to look for on hepatic MR i...</td>\n",
              "      <td>The presence of pneumobilia is a particular pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152076</th>\n",
              "      <td>348892</td>\n",
              "      <td>429188</td>\n",
              "      <td>[Relaparotomy or endoscopic surgery in complic...</td>\n",
              "      <td>The number of cases in bile duct surgery has c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174654</th>\n",
              "      <td>348892</td>\n",
              "      <td>10972182</td>\n",
              "      <td>The significance of personality in pain from g...</td>\n",
              "      <td>The aim of the study was to investigate the as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249609</th>\n",
              "      <td>348892</td>\n",
              "      <td>11475852</td>\n",
              "      <td>[Ductal calculi as a diagnostic and therapeuti...</td>\n",
              "      <td>Currently used techniques of CBD lithiasis tre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        user_id       pid                                              title  \\\n",
              "175227   348892   1292768  [Percutaneous removal of residual calculi of t...   \n",
              "153482   348892  22104745                       Update in biliary endoscopy.   \n",
              "2962     348892   9171132  Long-term results after laparoscopic cholecyst...   \n",
              "247775   348892  16968186  Multilocular flank abscess due to stone migrat...   \n",
              "4153     348892  22519190  Dietary habits as a risk factor of gallstone d...   \n",
              "174710   348892   1670228  Results of laparoscopic cholecystectomy in a u...   \n",
              "10031    348892  16391906  Pneumobilia: where to look for on hepatic MR i...   \n",
              "152076   348892    429188  [Relaparotomy or endoscopic surgery in complic...   \n",
              "174654   348892  10972182  The significance of personality in pain from g...   \n",
              "249609   348892  11475852  [Ductal calculi as a diagnostic and therapeuti...   \n",
              "\n",
              "                                                 abstract  \n",
              "175227  Percutaneous instrumentation under fluoroscopi...  \n",
              "153482  Biliary endoscopy has seen the development of ...  \n",
              "2962    Cholecystotomy has been suggested for symptoma...  \n",
              "247775  We report a case of a patient who presented wi...  \n",
              "4153    Gallstone formation is a multifactorial diseas...  \n",
              "174710  This study analyzed the first 100 laparoscopic...  \n",
              "10031   The presence of pneumobilia is a particular pr...  \n",
              "152076  The number of cases in bile duct surgery has c...  \n",
              "174654  The aim of the study was to investigate the as...  \n",
              "249609  Currently used techniques of CBD lithiasis tre...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3OgPussUHOj",
        "colab_type": "code",
        "outputId": "31765b4f-26c1-4a05-b669-346d58cd7d71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "recommend(user_id= 348892, topn= 10, sample_user = 5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pid</th>\n",
              "      <th>score</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7970057</td>\n",
              "      <td>0.716025</td>\n",
              "      <td>[Diagnostic-operative laparoscopy. Our experie...</td>\n",
              "      <td>Diagnostic laparoscopy has been an integral pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23134185</td>\n",
              "      <td>0.708834</td>\n",
              "      <td>Surgical treatment of gastrinomas: a single-ce...</td>\n",
              "      <td>Gastrinomas are rare neuroendocrine tumours, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25400740</td>\n",
              "      <td>0.700779</td>\n",
              "      <td>Endoscopic interventional treatment for gastri...</td>\n",
              "      <td>Endoscopic Interventional Treatment is of litt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17907973</td>\n",
              "      <td>0.690769</td>\n",
              "      <td>Single-center experience of laparoscopic chole...</td>\n",
              "      <td>The laparoscopic cholecystectomy procedure is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18756345</td>\n",
              "      <td>0.688988</td>\n",
              "      <td>Gallstone ileus: retrospective review of a sin...</td>\n",
              "      <td>Gallstone ileus is responsible for 1-3 percent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>16282958</td>\n",
              "      <td>0.979679</td>\n",
              "      <td>Endoscopy for bile duct stones.</td>\n",
              "      <td>In the era of laparoscopic cholecystectomy and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9828727</td>\n",
              "      <td>0.957200</td>\n",
              "      <td>Choledochoduodenostomy for common bile duct st...</td>\n",
              "      <td>Among the techniques for dealing with common b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7426929</td>\n",
              "      <td>0.950031</td>\n",
              "      <td>Endoscopic sphincterotomy for bile duct stones.</td>\n",
              "      <td>This paper reports the results of endoscopic s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10955066</td>\n",
              "      <td>0.949220</td>\n",
              "      <td>[Laparoscopy for common bile duct stones].</td>\n",
              "      <td>We performed 75 laparoscopic cholecystectomies...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>17701853</td>\n",
              "      <td>0.947592</td>\n",
              "      <td>Balloon sphincteroplasty for removing difficul...</td>\n",
              "      <td>Extraction of common bile duct stones at endos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        pid     score                                              title  \\\n",
              "0   7970057  0.716025  [Diagnostic-operative laparoscopy. Our experie...   \n",
              "1  23134185  0.708834  Surgical treatment of gastrinomas: a single-ce...   \n",
              "2  25400740  0.700779  Endoscopic interventional treatment for gastri...   \n",
              "3  17907973  0.690769  Single-center experience of laparoscopic chole...   \n",
              "4  18756345  0.688988  Gallstone ileus: retrospective review of a sin...   \n",
              "5  16282958  0.979679                    Endoscopy for bile duct stones.   \n",
              "6   9828727  0.957200  Choledochoduodenostomy for common bile duct st...   \n",
              "7   7426929  0.950031    Endoscopic sphincterotomy for bile duct stones.   \n",
              "8  10955066  0.949220         [Laparoscopy for common bile duct stones].   \n",
              "9  17701853  0.947592  Balloon sphincteroplasty for removing difficul...   \n",
              "\n",
              "                                            abstract  \n",
              "0  Diagnostic laparoscopy has been an integral pa...  \n",
              "1  Gastrinomas are rare neuroendocrine tumours, a...  \n",
              "2  Endoscopic Interventional Treatment is of litt...  \n",
              "3  The laparoscopic cholecystectomy procedure is ...  \n",
              "4  Gallstone ileus is responsible for 1-3 percent...  \n",
              "5  In the era of laparoscopic cholecystectomy and...  \n",
              "6  Among the techniques for dealing with common b...  \n",
              "7  This paper reports the results of endoscopic s...  \n",
              "8  We performed 75 laparoscopic cholecystectomies...  \n",
              "9  Extraction of common bile duct stones at endos...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT9KuOZyVsBS",
        "colab_type": "text"
      },
      "source": [
        "RESPONDER:\n",
        "- ¿Qué problemas puede tener la recomendación basada en contenido?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udiRZZeyaino",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}