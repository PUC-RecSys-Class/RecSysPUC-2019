{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralRankingTutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8zvIoMyLVjK",
        "colab_type": "text"
      },
      "source": [
        "# Práctico Learning to Rank: Deep Neural Ranking Tutorial \n",
        "- En este tutorial probaremos rendimiento de deep neural ranking utilizando el dataset ANTIQUE de question answering de Yahoo!. \n",
        "- Recordar que un modelo de ranking necesita de una función de scoring, una función de pérdida, queries y documentos candidatos. Por lo que probaremos funciones de ranking y funciones de pérdida y compararemos sus resultados.\n",
        "- La idea es que con este tutorial, ustedes puedan replicar esta metodología aplicada a otros dominios. \n",
        "\n",
        "**Ayudantes**: Andrés Carvallo, Manuel Cartagena y Patricio Cerda. \\\\\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sDPC4XtNEjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import six\n",
        "import os\n",
        "import numpy as np\n",
        "from google.protobuf import text_format\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "  import tensorflow_ranking as tfr\n",
        "except ImportError:\n",
        "    !pip install -q tensorflow_ranking\n",
        "    import tensorflow_ranking as tfr\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "tf.executing_eagerly()\n",
        "tf.set_random_seed(1234)\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK-hSp0z_N4W",
        "colab_type": "code",
        "outputId": "386afe26-ac57-4a59-ff9f-34a34728ad1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEBXpDkvMwaO",
        "colab_type": "text"
      },
      "source": [
        "# Descarga de dataset ANTIQUE (yahoo answers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ5mXuY8LVGe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "e93541db-37af-4c44-9b35-3f65799eae94"
      },
      "source": [
        "!wget -O \"/tmp/vocab.txt\" \"http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/vocab.txt\"\n",
        "!wget -O \"/tmp/train.tfrecords\" \"http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/train.tfrecords\"\n",
        "!wget -O \"/tmp/test.tfrecords\" \"http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/test.tfrecords\""
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-16 16:14:19--  http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/vocab.txt\n",
            "Resolving ciir.cs.umass.edu (ciir.cs.umass.edu)... 128.119.246.154\n",
            "Connecting to ciir.cs.umass.edu (ciir.cs.umass.edu)|128.119.246.154|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 231508 (226K) [text/plain]\n",
            "Saving to: ‘/tmp/vocab.txt’\n",
            "\n",
            "/tmp/vocab.txt      100%[===================>] 226.08K   331KB/s    in 0.7s    \n",
            "\n",
            "2019-09-16 16:14:20 (331 KB/s) - ‘/tmp/vocab.txt’ saved [231508/231508]\n",
            "\n",
            "--2019-09-16 16:14:21--  http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/train.tfrecords\n",
            "Resolving ciir.cs.umass.edu (ciir.cs.umass.edu)... 128.119.246.154\n",
            "Connecting to ciir.cs.umass.edu (ciir.cs.umass.edu)|128.119.246.154|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 156570056 (149M)\n",
            "Saving to: ‘/tmp/train.tfrecords’\n",
            "\n",
            "/tmp/train.tfrecord 100%[===================>] 149.32M  11.8MB/s    in 14s     \n",
            "\n",
            "2019-09-16 16:14:35 (10.8 MB/s) - ‘/tmp/train.tfrecords’ saved [156570056/156570056]\n",
            "\n",
            "--2019-09-16 16:14:37--  http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/test.tfrecords\n",
            "Resolving ciir.cs.umass.edu (ciir.cs.umass.edu)... 128.119.246.154\n",
            "Connecting to ciir.cs.umass.edu (ciir.cs.umass.edu)|128.119.246.154|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12445747 (12M)\n",
            "Saving to: ‘/tmp/test.tfrecords’\n",
            "\n",
            "/tmp/test.tfrecords 100%[===================>]  11.87M  5.92MB/s    in 2.0s    \n",
            "\n",
            "2019-09-16 16:14:39 (5.92 MB/s) - ‘/tmp/test.tfrecords’ saved [12445747/12445747]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wId0aWeM2uP",
        "colab_type": "text"
      },
      "source": [
        "#  Formato de los datos para entregárselos al modelo \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71IYAMpzSjmn",
        "colab_type": "text"
      },
      "source": [
        "## Formato de las queries (ejemplos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw9RVsBuM_fq",
        "colab_type": "code",
        "outputId": "5537068a-ce77-43f1-a751-9399c61d3dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "QUERY = text_format.Parse(\n",
        "    \"\"\"\n",
        "    features {\n",
        "      feature {\n",
        "        key: \"query_tokens\"\n",
        "        value { bytes_list { value: [\"what\", \"are\", \"the\", \"benefits\" , \"of\", \"drinking\", \"coffee\", \"?\"] } }\n",
        "      }\n",
        "    }\"\"\", tf.train.Example())\n",
        "\n",
        "print(QUERY)\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features {\n",
            "  feature {\n",
            "    key: \"query_tokens\"\n",
            "    value {\n",
            "      bytes_list {\n",
            "        value: \"what\"\n",
            "        value: \"are\"\n",
            "        value: \"the\"\n",
            "        value: \"benefits\"\n",
            "        value: \"of\"\n",
            "        value: \"drinking\"\n",
            "        value: \"coffee\"\n",
            "        value: \"?\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P9CrGokSmNV",
        "colab_type": "text"
      },
      "source": [
        "##Formato de los documentos (ejemplos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QiFBo-9Smjo",
        "colab_type": "code",
        "outputId": "5db86b08-6168-4a7c-a70c-ecd9f75d970e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "DOCUMENTS = [\n",
        "             \n",
        "    # ejemplo de documento RELEVANTE (1)  \n",
        "    text_format.Parse(\n",
        "    \"\"\"\n",
        "    features {\n",
        "      feature {\n",
        "        key: \"document_tokens\"\n",
        "        value { bytes_list { value: [\"wake\", \"up\", \"the\", \"mind\", \"give\", \"energy\", \"contain\", \"antioxidants\", \"in\", \"fact\", \"recommend\", \"two\", \"cups\", \"a\", \"day\"] } }\n",
        "      }\n",
        "      feature {\n",
        "        key: \"relevance\"\n",
        "        value { int64_list { value: 1 } }\n",
        "      }\n",
        "    }\"\"\", tf.train.Example()),\n",
        "\n",
        "    # ejemplo de documento NO RELEVANTE (0)\n",
        "    text_format.Parse(\n",
        "        \"\"\"\n",
        "    features {\n",
        "      feature {\n",
        "        key: \"document_tokens\"\n",
        "        value { bytes_list { value: [\"clouds\", \"are\", \"white\"] } }\n",
        "      }\n",
        "      feature {\n",
        "        key: \"relevance\"\n",
        "        value { int64_list { value: 0 } }\n",
        "      }\n",
        "    }\"\"\", tf.train.Example()),\n",
        "]\n",
        "\n",
        "print(DOCUMENTS)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[features {\n",
            "  feature {\n",
            "    key: \"document_tokens\"\n",
            "    value {\n",
            "      bytes_list {\n",
            "        value: \"wake\"\n",
            "        value: \"up\"\n",
            "        value: \"the\"\n",
            "        value: \"mind\"\n",
            "        value: \"give\"\n",
            "        value: \"energy\"\n",
            "        value: \"contain\"\n",
            "        value: \"antioxidants\"\n",
            "        value: \"in\"\n",
            "        value: \"fact\"\n",
            "        value: \"recommend\"\n",
            "        value: \"two\"\n",
            "        value: \"cups\"\n",
            "        value: \"a\"\n",
            "        value: \"day\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  feature {\n",
            "    key: \"relevance\"\n",
            "    value {\n",
            "      int64_list {\n",
            "        value: 1\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", features {\n",
            "  feature {\n",
            "    key: \"document_tokens\"\n",
            "    value {\n",
            "      bytes_list {\n",
            "        value: \"clouds\"\n",
            "        value: \"are\"\n",
            "        value: \"white\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  feature {\n",
            "    key: \"relevance\"\n",
            "    value {\n",
            "      int64_list {\n",
            "        value: 0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDi_2GdsNAIC",
        "colab_type": "text"
      },
      "source": [
        "# Definición de hiperparámetros y split de datos en set de train y test para la evaluación del modelo "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh7K3N5ANP_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_TRAIN_DATA_PATH = \"/tmp/train.tfrecords\"\n",
        "_TEST_DATA_PATH = \"/tmp/test.tfrecords\"\n",
        "_VOCAB_PATH = \"/tmp/vocab.txt\"\n",
        "\n",
        "# Definimos el maximo de documentos por query (si tiene menos de ese numero aplica padding)\n",
        "_LIST_SIZE = 50\n",
        "\n",
        "# Nombre del feature, en este caso relevante/no relevante.\n",
        "_LABEL_FEATURE = \"relevance\"\n",
        "\n",
        "# Documentos que estan en padding son ignorados para la funcion de perdida, por eso se le asigna un -1 \n",
        "_PADDING_LABEL = -1\n",
        "\n",
        "_LEARNING_RATE = 0.05\n",
        "\n",
        "# Parametros para funcion de scoring \n",
        "_BATCH_SIZE = 32\n",
        "_HIDDEN_LAYER_DIMS = [\"64\", \"32\", \"16\"] # 3 capas, la primera de 64 neuronas, segunda de 32 y la tercera de 16 \n",
        "_DROPOUT_RATE = 0.8\n",
        "_GROUP_SIZE = 5  # 1 si es pointwise, 2 pairwise y mas de 2 listwise.\n",
        "\n",
        "# Path donde guardaremos el modelo y la cantidad de steps de entrenamiento \n",
        "_MODEL_DIR = \"/tmp/ranking_model_dir\"\n",
        "_NUM_TRAIN_STEPS = 15000 # pasos de entrenamiento 15,000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCzcmGzjNlch",
        "colab_type": "text"
      },
      "source": [
        "# Arquitectura del modelo de ranking \n",
        "- **Data Loader:** toma los datos raw y los convierte a formato en que los recice el feature extractor.  \n",
        "- **Feature transformation:** Transformador de datos a features para el ranker.  \n",
        "- **Función de scoring:** pointwise, pairwise, listwise.  \n",
        "- **Función de pérdida:** sigmoid cross entropy (pointwise),  logistic loss (pairwise), softmax cross entropy (listwise) \n",
        "- **Métricas de evaluación de resultados de ranking:** nDCG, MRR, etc... \n",
        "- **Ranking Head:** combina funcion de ranking, funcion de pérdida y metricas de evaluación en un mismo módulo. \n",
        "- **Model builder:** construye modelo definitivo de ranking. \n",
        "\n",
        "![tf_ranking_arch](https://user-images.githubusercontent.com/3262617/60061785-5f107980-96ab-11e9-9849-ace2d117220f.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jODj4lw-VoY",
        "colab_type": "text"
      },
      "source": [
        "## Especificamos features via Feature Columns \n",
        "- Primero asocia cada palabra a su index en el vocabulario.  \n",
        "- Luego convierte esta lista de tokens a lista de embeddings que se inicializan aleatorios y el modelo los aprende en el training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFBNujGHOZXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_EMBEDDING_DIMENSION = 20\n",
        "\n",
        "# context == query \n",
        "def context_feature_columns():\n",
        "  sparse_column = tf.feature_column.categorical_column_with_vocabulary_file(key=\"query_tokens\",vocabulary_file=_VOCAB_PATH)\n",
        "  query_embedding_column = tf.feature_column.embedding_column(sparse_column, _EMBEDDING_DIMENSION)\n",
        "  return {\"query_tokens\": query_embedding_column}\n",
        "\n",
        "# example == documento \n",
        "def example_feature_columns():\n",
        "  sparse_column = tf.feature_column.categorical_column_with_vocabulary_file(key=\"document_tokens\",vocabulary_file=_VOCAB_PATH)\n",
        "  document_embedding_column = tf.feature_column.embedding_column(sparse_column, _EMBEDDING_DIMENSION)\n",
        "  \n",
        "  return {\"document_tokens\": document_embedding_column}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2klSjDCU-vR1",
        "colab_type": "text"
      },
      "source": [
        "## Leer input data utilizando input_fn (data loader: agrupar datos en batch para dárselos a la red)\n",
        "- Convierte datos de entrada en tensores y al tipo que correspondan los valores (i.e float, int, etc...)\n",
        "- Features de los documentos se representan como tensores de 3 dimensiones (queries, documentos y valores de features) \n",
        "- Features de las queries son tensores de 2 dimensiones (queries y valores de sus features). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbFQexR-_Gct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn(path, num_epochs=None):\n",
        "  context_feature_spec = tf.feature_column.make_parse_example_spec(context_feature_columns().values())\n",
        "  label_column = tf.feature_column.numeric_column(_LABEL_FEATURE, dtype=tf.int64, default_value=_PADDING_LABEL)\n",
        "  example_feature_spec = tf.feature_column.make_parse_example_spec(list(example_feature_columns().values()) + [label_column])\n",
        "  \n",
        "  # LOAD DATASET IN BATCH, SPECIFY WHICH COLUMNS ARE QUERY FEATURES AND WHICH ONES ARE DOCUMENT FEATURES \n",
        "  dataset = tfr.data.build_ranking_dataset(file_pattern=path,\n",
        "        data_format=tfr.data.EIE,\n",
        "        batch_size=_BATCH_SIZE,\n",
        "        list_size=_LIST_SIZE,\n",
        "        context_feature_spec=context_feature_spec,\n",
        "        example_feature_spec=example_feature_spec,\n",
        "        reader=tf.data.TFRecordDataset,\n",
        "        shuffle=False,\n",
        "        num_epochs=num_epochs)\n",
        "  \n",
        "  # RESHAPE FEATURES AND LABELS FOR RANKING MODEL TRAINING \n",
        "  features = tf.data.make_one_shot_iterator(dataset).get_next()\n",
        "  label = tf.squeeze(features.pop(_LABEL_FEATURE), axis=2)\n",
        "  label = tf.cast(label, tf.float32)\n",
        "  return features, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4BHTNyE_2CU",
        "colab_type": "text"
      },
      "source": [
        "## Transformación de features: transform_fn\n",
        "- Transforma features sparse a dense features para que sean recibidos por la red  \n",
        "- Reshape de features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXAn8dcY_yxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_transform_fn():\n",
        "  def _transform_fn(features, mode):\n",
        "    example_name = next(six.iterkeys(example_feature_columns()))\n",
        "    input_size = tf.shape(input=features[example_name])[1]\n",
        "\n",
        "    # GROUP QUERY FEATURES AND DOCUMENT FEATURES IN POINTWISE, PAIRWISE AND/OR LISTWISE FORMAT DEPENDING ON WHAT WE CHOSE EARLIER \n",
        "    context_features, example_features = tfr.feature.encode_listwise_features(features=features,input_size=input_size,\n",
        "                                                                              context_feature_columns=context_feature_columns(), \n",
        "                                                                              example_feature_columns=example_feature_columns(), \n",
        "                                                                              mode=mode,\n",
        "                                                                              scope=\"transform_layer\")\n",
        "\n",
        "    return context_features, example_features \n",
        "  return _transform_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBwYESCRAk8Z",
        "colab_type": "text"
      },
      "source": [
        "## Scoring Function \n",
        "- La idea es calcular una puntuación de relevancia para un (conjunto de) par (s) de query-documento\n",
        "- El modelo TF-Ranking utilizará datos de entrenamiento para aprender esta función.\n",
        "- Aquí formulamos una función de scoring utilizando una red neuronal feed-forward.\n",
        "- La función toma las características de un solo ejemplo (es decir, par de query-documento) y retorna un score de relevancia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6dTGlOMAh30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_score_fn():\n",
        "  def _score_fn(context_features, group_features, mode, params, config):\n",
        "    with tf.compat.v1.name_scope(\"input_layer\"):\n",
        "      context_input = [tf.compat.v1.layers.flatten(context_features[name]) for name in sorted(context_feature_columns())]\n",
        "      group_input = [tf.compat.v1.layers.flatten(group_features[name]) for name in sorted(example_feature_columns())]\n",
        "      input_layer = tf.concat(context_input + group_input, 1)\n",
        "\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    cur_layer = input_layer\n",
        "    cur_layer = tf.compat.v1.layers.batch_normalization(cur_layer,training=is_training,momentum=0.99)\n",
        "\n",
        "    for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
        "      cur_layer = tf.compat.v1.layers.dense(cur_layer, units=layer_width)\n",
        "      cur_layer = tf.compat.v1.layers.batch_normalization(cur_layer,training=is_training,momentum=0.99)\n",
        "      cur_layer = tf.nn.relu(cur_layer)\n",
        "      cur_layer = tf.compat.v1.layers.dropout(inputs=cur_layer, rate=_DROPOUT_RATE, training=is_training)\n",
        "    logits = tf.compat.v1.layers.dense(cur_layer, units=_GROUP_SIZE)\n",
        "    return logits\n",
        "\n",
        "  return _score_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNIDekFwBbV1",
        "colab_type": "text"
      },
      "source": [
        "## Métricas de evaluación \n",
        "- ndcg@1, 3,5,10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk4fdhaPBUaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_metric_fns():\n",
        "  metric_fns = {}\n",
        "  metric_fns.update({\n",
        "      \"metric/ndcg@%d\" % topn: tfr.metrics.make_ranking_metric_fn(\n",
        "          tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
        "      for topn in [1, 3, 5, 10]\n",
        "  })\n",
        "\n",
        "  return metric_fns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3qSGBTkBtFM",
        "colab_type": "text"
      },
      "source": [
        "## Función de pérdida "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEpozP0OBku9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Puede ser cualquiera de estas funciones de perdida \n",
        "'''\n",
        "PAIRWISE_HINGE_LOSS\n",
        "PAIRWISE_LOGISTIC_LOSS (PAIRWISE) # recordar cambiar arriba GROUP_SIZE por 2 \n",
        "PAIRWISE_SOFT_ZERO_ONE_LOSS\n",
        "SOFTMAX_LOSS (LISTWISE)\n",
        "SIGMOID_CROSS_ENTROPY_LOSS (POINTWISE)\n",
        "MEAN_SQUARED_LOSS\n",
        "LIST_MLE_LOSS\n",
        "APPROX_NDCG_LOSS\n",
        "'''\n",
        "\n",
        "_LOSS = tfr.losses.RankingLossKey.SOFTMAX_LOSS\n",
        "\n",
        "loss_fn = tfr.losses.make_loss_fn(_LOSS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6cXogn8B35M",
        "colab_type": "text"
      },
      "source": [
        "## Ranking Head \n",
        "- Aqui se juntan funciones de perdida, optimizador y métrica de evaluación del modelo en un mismo módulo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKP3lh1HB1gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.compat.v1.train.AdagradOptimizer(learning_rate=_LEARNING_RATE)\n",
        "\n",
        "def _train_op_fn(loss):\n",
        "  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "  minimize_op = optimizer.minimize(loss=loss, global_step=tf.compat.v1.train.get_global_step())\n",
        "  train_op = tf.group([update_ops, minimize_op])\n",
        "  return train_op\n",
        "\n",
        "ranking_head = tfr.head.create_ranking_head(loss_fn=loss_fn, eval_metric_fns=eval_metric_fns(),train_op_fn=_train_op_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERm3CykVCSwV",
        "colab_type": "text"
      },
      "source": [
        "## Juntamos todo en un Model Builder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqFrJ8jsCXnY",
        "colab_type": "code",
        "outputId": "96a46125-c28c-4e32-e9c6-f73331610f1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_fn = tfr.model.make_groupwise_ranking_fn(\n",
        "          group_score_fn=make_score_fn(),\n",
        "          transform_fn=make_transform_fn(),\n",
        "          group_size=_GROUP_SIZE,\n",
        "          ranking_head=ranking_head)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Building groupwise ranking model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCkmBL8XCdEV",
        "colab_type": "text"
      },
      "source": [
        "## Función de entrenamiento y evaluación del ranker "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs78uQtGCfGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_eval_fn():\n",
        "  run_config = tf.estimator.RunConfig(save_checkpoints_steps=1000) # SAVE MODEL EACH 1,000 STEPS \n",
        "  ranker = tf.estimator.Estimator(\n",
        "      model_fn=model_fn,\n",
        "      model_dir=_MODEL_DIR,\n",
        "      config=run_config)\n",
        "\n",
        "  train_input_fn = lambda: input_fn(_TRAIN_DATA_PATH)\n",
        "  eval_input_fn = lambda: input_fn(_TEST_DATA_PATH, num_epochs=1)\n",
        "\n",
        "  train_spec = tf.estimator.TrainSpec(\n",
        "      input_fn=train_input_fn, max_steps=_NUM_TRAIN_STEPS)\n",
        "  \n",
        "  eval_spec =  tf.estimator.EvalSpec(\n",
        "          name=\"eval\",\n",
        "          input_fn=eval_input_fn,\n",
        "          throttle_secs=15)\n",
        "  \n",
        "  return (ranker, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnKlTexkCn9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6473ef9-a61b-4a28-c4ec-6c976b1f016c"
      },
      "source": [
        "! rm -rf \"/tmp/ranking_model_dir\"  # elimina dir del modelo anterior para ver resultados de un nuevo ranker.\n",
        "ranker, train_spec, eval_spec = train_and_eval_fn()\n",
        "tf.estimator.train_and_evaluate(ranker, train_spec, eval_spec)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/ranking_model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f834197c320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function _make_model_fn.<locals>._model_fn at 0x7f8342c88d08>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:loss = 80.27193, step = 0\n",
            "INFO:tensorflow:global_step/sec: 40.6281\n",
            "INFO:tensorflow:loss = 70.24902, step = 100 (2.464 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.5729\n",
            "INFO:tensorflow:loss = 42.099045, step = 200 (2.061 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.2114\n",
            "INFO:tensorflow:loss = 58.349026, step = 300 (2.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.8464\n",
            "INFO:tensorflow:loss = 53.152554, step = 400 (2.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.5365\n",
            "INFO:tensorflow:loss = 61.591965, step = 500 (2.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.6754\n",
            "INFO:tensorflow:loss = 81.20418, step = 600 (2.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.7269\n",
            "INFO:tensorflow:loss = 57.9149, step = 700 (2.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.0856\n",
            "INFO:tensorflow:loss = 62.40436, step = 800 (2.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.2324\n",
            "INFO:tensorflow:loss = 60.21753, step = 900 (2.210 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:16:07Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:16:08\n",
            "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, labels_mean = 1.9630322, logits_mean = -0.00014678162, loss = 50.320213, metric/ndcg@1 = 0.5971428, metric/ndcg@10 = 0.7813622, metric/ndcg@3 = 0.65706736, metric/ndcg@5 = 0.7029691\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/ranking_model_dir/model.ckpt-1000\n",
            "INFO:tensorflow:global_step/sec: 18.9184\n",
            "INFO:tensorflow:loss = 60.61113, step = 1000 (5.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0905\n",
            "INFO:tensorflow:loss = 58.356625, step = 1100 (2.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.7991\n",
            "INFO:tensorflow:loss = 77.02023, step = 1200 (2.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.7338\n",
            "INFO:tensorflow:loss = 72.707924, step = 1300 (2.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.796\n",
            "INFO:tensorflow:loss = 52.311806, step = 1400 (2.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.829\n",
            "INFO:tensorflow:loss = 59.97728, step = 1500 (2.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.5409\n",
            "INFO:tensorflow:loss = 67.81902, step = 1600 (2.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.0409\n",
            "INFO:tensorflow:loss = 60.26126, step = 1700 (2.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5393\n",
            "INFO:tensorflow:loss = 48.273216, step = 1800 (2.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.02\n",
            "INFO:tensorflow:loss = 82.134155, step = 1900 (2.272 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:16:33Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:16:34\n",
            "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, labels_mean = 1.9630322, logits_mean = -0.00012154327, loss = 50.32022, metric/ndcg@1 = 0.5857143, metric/ndcg@10 = 0.770384, metric/ndcg@3 = 0.6429268, metric/ndcg@5 = 0.688242\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /tmp/ranking_model_dir/model.ckpt-2000\n",
            "INFO:tensorflow:global_step/sec: 19.2357\n",
            "INFO:tensorflow:loss = 64.356346, step = 2000 (5.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.6867\n",
            "INFO:tensorflow:loss = 66.36046, step = 2100 (2.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.8421\n",
            "INFO:tensorflow:loss = 61.38948, step = 2200 (2.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.8869\n",
            "INFO:tensorflow:loss = 56.16077, step = 2300 (2.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.778\n",
            "INFO:tensorflow:loss = 90.49133, step = 2400 (2.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.8016\n",
            "INFO:tensorflow:loss = 62.10216, step = 2500 (2.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.475\n",
            "INFO:tensorflow:loss = 55.46398, step = 2600 (2.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.8291\n",
            "INFO:tensorflow:loss = 54.03077, step = 2700 (2.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0496\n",
            "INFO:tensorflow:loss = 52.39466, step = 2800 (2.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.3135\n",
            "INFO:tensorflow:loss = 69.17256, step = 2900 (2.258 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:16:58Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-3000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:16:59\n",
            "INFO:tensorflow:Saving dict for global step 3000: global_step = 3000, labels_mean = 1.9630322, logits_mean = -9.30917e-05, loss = 50.32012, metric/ndcg@1 = 0.57357144, metric/ndcg@10 = 0.78533477, metric/ndcg@3 = 0.6474301, metric/ndcg@5 = 0.7081455\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: /tmp/ranking_model_dir/model.ckpt-3000\n",
            "INFO:tensorflow:global_step/sec: 18.663\n",
            "INFO:tensorflow:loss = 60.80943, step = 3000 (5.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.3623\n",
            "INFO:tensorflow:loss = 66.587006, step = 3100 (2.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5873\n",
            "INFO:tensorflow:loss = 57.748123, step = 3200 (2.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5854\n",
            "INFO:tensorflow:loss = 50.212578, step = 3300 (2.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.2164\n",
            "INFO:tensorflow:loss = 55.264854, step = 3400 (2.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.475\n",
            "INFO:tensorflow:loss = 53.745937, step = 3500 (2.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5132\n",
            "INFO:tensorflow:loss = 71.71331, step = 3600 (2.249 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.6687\n",
            "INFO:tensorflow:loss = 51.021408, step = 3700 (2.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.5683\n",
            "INFO:tensorflow:loss = 46.21341, step = 3800 (2.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.5464\n",
            "INFO:tensorflow:loss = 64.46152, step = 3900 (2.198 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:17:23Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-4000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:17:24\n",
            "INFO:tensorflow:Saving dict for global step 4000: global_step = 4000, labels_mean = 1.9630322, logits_mean = -0.0002473983, loss = 50.31973, metric/ndcg@1 = 0.5814286, metric/ndcg@10 = 0.78371215, metric/ndcg@3 = 0.65794593, metric/ndcg@5 = 0.7034062\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: /tmp/ranking_model_dir/model.ckpt-4000\n",
            "INFO:tensorflow:global_step/sec: 19.2285\n",
            "INFO:tensorflow:loss = 63.63501, step = 4000 (5.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.6705\n",
            "INFO:tensorflow:loss = 57.0382, step = 4100 (2.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.599\n",
            "INFO:tensorflow:loss = 40.507877, step = 4200 (2.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9407\n",
            "INFO:tensorflow:loss = 47.830482, step = 4300 (2.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.565\n",
            "INFO:tensorflow:loss = 56.940636, step = 4400 (2.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.1045\n",
            "INFO:tensorflow:loss = 60.235027, step = 4500 (2.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.5646\n",
            "INFO:tensorflow:loss = 59.340157, step = 4600 (2.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.069\n",
            "INFO:tensorflow:loss = 67.391785, step = 4700 (2.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.3375\n",
            "INFO:tensorflow:loss = 60.847816, step = 4800 (2.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.0891\n",
            "INFO:tensorflow:loss = 44.435482, step = 4900 (2.268 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:17:48Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:17:49\n",
            "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, labels_mean = 1.9630322, logits_mean = -0.00036884795, loss = 50.319214, metric/ndcg@1 = 0.57857144, metric/ndcg@10 = 0.7805679, metric/ndcg@3 = 0.65458274, metric/ndcg@5 = 0.7074179\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/ranking_model_dir/model.ckpt-5000\n",
            "INFO:tensorflow:global_step/sec: 18.3336\n",
            "INFO:tensorflow:loss = 57.406693, step = 5000 (5.455 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.7882\n",
            "INFO:tensorflow:loss = 60.901833, step = 5100 (2.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.6112\n",
            "INFO:tensorflow:loss = 55.260838, step = 5200 (2.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.5347\n",
            "INFO:tensorflow:loss = 51.268173, step = 5300 (2.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.8788\n",
            "INFO:tensorflow:loss = 46.44713, step = 5400 (2.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.839\n",
            "INFO:tensorflow:loss = 70.12938, step = 5500 (2.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.4085\n",
            "INFO:tensorflow:loss = 49.952408, step = 5600 (2.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.4723\n",
            "INFO:tensorflow:loss = 59.14985, step = 5700 (2.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.2528\n",
            "INFO:tensorflow:loss = 50.82883, step = 5800 (2.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.3259\n",
            "INFO:tensorflow:loss = 75.58524, step = 5900 (2.209 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 6000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:18:14Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-6000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:18:15\n",
            "INFO:tensorflow:Saving dict for global step 6000: global_step = 6000, labels_mean = 1.9630322, logits_mean = -0.00083778717, loss = 50.316998, metric/ndcg@1 = 0.60714287, metric/ndcg@10 = 0.78430504, metric/ndcg@3 = 0.6582514, metric/ndcg@5 = 0.70217377\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: /tmp/ranking_model_dir/model.ckpt-6000\n",
            "INFO:tensorflow:global_step/sec: 19.2138\n",
            "INFO:tensorflow:loss = 66.96641, step = 6000 (5.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.2899\n",
            "INFO:tensorflow:loss = 60.284615, step = 6100 (2.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.2265\n",
            "INFO:tensorflow:loss = 71.7818, step = 6200 (2.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.4838\n",
            "INFO:tensorflow:loss = 70.87698, step = 6300 (2.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0822\n",
            "INFO:tensorflow:loss = 59.359173, step = 6400 (2.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.6811\n",
            "INFO:tensorflow:loss = 43.254013, step = 6500 (2.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.0038\n",
            "INFO:tensorflow:loss = 67.70885, step = 6600 (2.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.809\n",
            "INFO:tensorflow:loss = 60.31989, step = 6700 (2.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.484\n",
            "INFO:tensorflow:loss = 65.18678, step = 6800 (2.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9395\n",
            "INFO:tensorflow:loss = 57.90239, step = 6900 (2.224 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 7000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:18:39Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-7000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:18:40\n",
            "INFO:tensorflow:Saving dict for global step 7000: global_step = 7000, labels_mean = 1.9630322, logits_mean = -0.0018611833, loss = 50.312107, metric/ndcg@1 = 0.6307143, metric/ndcg@10 = 0.7951611, metric/ndcg@3 = 0.6680745, metric/ndcg@5 = 0.7128171\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: /tmp/ranking_model_dir/model.ckpt-7000\n",
            "INFO:tensorflow:global_step/sec: 19.0406\n",
            "INFO:tensorflow:loss = 51.95207, step = 7000 (5.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0305\n",
            "INFO:tensorflow:loss = 76.22229, step = 7100 (2.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.3762\n",
            "INFO:tensorflow:loss = 72.507706, step = 7200 (2.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.5935\n",
            "INFO:tensorflow:loss = 74.73968, step = 7300 (2.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.1821\n",
            "INFO:tensorflow:loss = 53.7305, step = 7400 (2.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.2017\n",
            "INFO:tensorflow:loss = 49.0719, step = 7500 (2.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.2142\n",
            "INFO:tensorflow:loss = 73.35528, step = 7600 (2.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.3276\n",
            "INFO:tensorflow:loss = 58.088226, step = 7700 (2.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.0128\n",
            "INFO:tensorflow:loss = 72.62778, step = 7800 (2.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.4849\n",
            "INFO:tensorflow:loss = 55.738205, step = 7900 (2.249 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 8000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:19:04Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-8000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:19:05\n",
            "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, labels_mean = 1.9630322, logits_mean = -0.0039620204, loss = 50.288822, metric/ndcg@1 = 0.6021429, metric/ndcg@10 = 0.8069417, metric/ndcg@3 = 0.6809114, metric/ndcg@5 = 0.7337862\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: /tmp/ranking_model_dir/model.ckpt-8000\n",
            "INFO:tensorflow:global_step/sec: 18.4009\n",
            "INFO:tensorflow:loss = 58.3705, step = 8000 (5.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.6411\n",
            "INFO:tensorflow:loss = 49.31989, step = 8100 (2.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.0928\n",
            "INFO:tensorflow:loss = 51.41263, step = 8200 (2.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.5287\n",
            "INFO:tensorflow:loss = 55.968685, step = 8300 (2.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.1731\n",
            "INFO:tensorflow:loss = 51.862976, step = 8400 (2.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.4786\n",
            "INFO:tensorflow:loss = 51.076004, step = 8500 (2.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5964\n",
            "INFO:tensorflow:loss = 50.299904, step = 8600 (2.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.2744\n",
            "INFO:tensorflow:loss = 84.2386, step = 8700 (2.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.7651\n",
            "INFO:tensorflow:loss = 65.4364, step = 8800 (2.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0196\n",
            "INFO:tensorflow:loss = 39.467323, step = 8900 (2.218 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:19:30Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-9000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:19:31\n",
            "INFO:tensorflow:Saving dict for global step 9000: global_step = 9000, labels_mean = 1.9630322, logits_mean = -0.011263485, loss = 50.24523, metric/ndcg@1 = 0.6457143, metric/ndcg@10 = 0.8085497, metric/ndcg@3 = 0.6900393, metric/ndcg@5 = 0.73976713\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9000: /tmp/ranking_model_dir/model.ckpt-9000\n",
            "INFO:tensorflow:global_step/sec: 19.1105\n",
            "INFO:tensorflow:loss = 37.32879, step = 9000 (5.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0031\n",
            "INFO:tensorflow:loss = 70.98677, step = 9100 (2.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.2077\n",
            "INFO:tensorflow:loss = 56.79193, step = 9200 (2.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0488\n",
            "INFO:tensorflow:loss = 67.27502, step = 9300 (2.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.5544\n",
            "INFO:tensorflow:loss = 54.653034, step = 9400 (2.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.6057\n",
            "INFO:tensorflow:loss = 63.4542, step = 9500 (2.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.7363\n",
            "INFO:tensorflow:loss = 38.711334, step = 9600 (2.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9385\n",
            "INFO:tensorflow:loss = 54.665733, step = 9700 (2.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.3034\n",
            "INFO:tensorflow:loss = 50.716423, step = 9800 (2.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.2293\n",
            "INFO:tensorflow:loss = 52.723385, step = 9900 (2.169 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:19:55Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:19:56\n",
            "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, labels_mean = 1.9630322, logits_mean = -0.018324258, loss = 50.202484, metric/ndcg@1 = 0.64285713, metric/ndcg@10 = 0.82076573, metric/ndcg@3 = 0.6943032, metric/ndcg@5 = 0.7589026\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/ranking_model_dir/model.ckpt-10000\n",
            "INFO:tensorflow:global_step/sec: 18.6667\n",
            "INFO:tensorflow:loss = 38.283127, step = 10000 (5.351 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0515\n",
            "INFO:tensorflow:loss = 49.38793, step = 10100 (2.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.3935\n",
            "INFO:tensorflow:loss = 61.57573, step = 10200 (2.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.8521\n",
            "INFO:tensorflow:loss = 48.474724, step = 10300 (2.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.2144\n",
            "INFO:tensorflow:loss = 43.948193, step = 10400 (2.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.9115\n",
            "INFO:tensorflow:loss = 52.44184, step = 10500 (2.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0908\n",
            "INFO:tensorflow:loss = 67.034645, step = 10600 (2.219 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5422\n",
            "INFO:tensorflow:loss = 62.4435, step = 10700 (2.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.8248\n",
            "INFO:tensorflow:loss = 60.01548, step = 10800 (2.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.4228\n",
            "INFO:tensorflow:loss = 80.398674, step = 10900 (2.251 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 11000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:20:20Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-11000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:20:21\n",
            "INFO:tensorflow:Saving dict for global step 11000: global_step = 11000, labels_mean = 1.9630322, logits_mean = -0.028663509, loss = 50.16087, metric/ndcg@1 = 0.625, metric/ndcg@10 = 0.82423764, metric/ndcg@3 = 0.71271574, metric/ndcg@5 = 0.76467484\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 11000: /tmp/ranking_model_dir/model.ckpt-11000\n",
            "INFO:tensorflow:global_step/sec: 19.0249\n",
            "INFO:tensorflow:loss = 68.1384, step = 11000 (5.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.9093\n",
            "INFO:tensorflow:loss = 84.87344, step = 11100 (2.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.2129\n",
            "INFO:tensorflow:loss = 47.754322, step = 11200 (2.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.7735\n",
            "INFO:tensorflow:loss = 70.262184, step = 11300 (2.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.4266\n",
            "INFO:tensorflow:loss = 68.74187, step = 11400 (2.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.8594\n",
            "INFO:tensorflow:loss = 63.684658, step = 11500 (2.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5459\n",
            "INFO:tensorflow:loss = 55.241947, step = 11600 (2.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.8424\n",
            "INFO:tensorflow:loss = 51.12558, step = 11700 (2.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.4453\n",
            "INFO:tensorflow:loss = 58.3047, step = 11800 (2.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0033\n",
            "INFO:tensorflow:loss = 66.99664, step = 11900 (2.222 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 12000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:20:46Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-12000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:20:47\n",
            "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, labels_mean = 1.9630322, logits_mean = -0.035525158, loss = 50.13199, metric/ndcg@1 = 0.6085714, metric/ndcg@10 = 0.81964064, metric/ndcg@3 = 0.7125043, metric/ndcg@5 = 0.7585629\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: /tmp/ranking_model_dir/model.ckpt-12000\n",
            "INFO:tensorflow:global_step/sec: 18.815\n",
            "INFO:tensorflow:loss = 73.88582, step = 12000 (5.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.1265\n",
            "INFO:tensorflow:loss = 57.134453, step = 12100 (2.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.4145\n",
            "INFO:tensorflow:loss = 63.71732, step = 12200 (2.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0723\n",
            "INFO:tensorflow:loss = 72.46221, step = 12300 (2.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5865\n",
            "INFO:tensorflow:loss = 47.78725, step = 12400 (2.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.371\n",
            "INFO:tensorflow:loss = 76.015945, step = 12500 (2.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.1864\n",
            "INFO:tensorflow:loss = 50.08996, step = 12600 (2.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.7928\n",
            "INFO:tensorflow:loss = 61.446278, step = 12700 (2.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.6589\n",
            "INFO:tensorflow:loss = 56.485962, step = 12800 (2.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.1435\n",
            "INFO:tensorflow:loss = 46.36238, step = 12900 (2.164 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 13000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:21:11Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-13000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:21:12\n",
            "INFO:tensorflow:Saving dict for global step 13000: global_step = 13000, labels_mean = 1.9630322, logits_mean = -0.048862226, loss = 50.093967, metric/ndcg@1 = 0.68857145, metric/ndcg@10 = 0.84635943, metric/ndcg@3 = 0.74903136, metric/ndcg@5 = 0.7821601\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13000: /tmp/ranking_model_dir/model.ckpt-13000\n",
            "INFO:tensorflow:global_step/sec: 19.4019\n",
            "INFO:tensorflow:loss = 39.590862, step = 13000 (5.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5185\n",
            "INFO:tensorflow:loss = 44.46235, step = 13100 (2.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.952\n",
            "INFO:tensorflow:loss = 59.81457, step = 13200 (2.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.0437\n",
            "INFO:tensorflow:loss = 68.78409, step = 13300 (2.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.5908\n",
            "INFO:tensorflow:loss = 69.592316, step = 13400 (2.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5664\n",
            "INFO:tensorflow:loss = 84.18004, step = 13500 (2.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.3126\n",
            "INFO:tensorflow:loss = 60.71505, step = 13600 (2.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5683\n",
            "INFO:tensorflow:loss = 48.3013, step = 13700 (2.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0734\n",
            "INFO:tensorflow:loss = 71.30732, step = 13800 (2.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.4176\n",
            "INFO:tensorflow:loss = 47.893364, step = 13900 (2.250 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 14000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:21:36Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-14000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:21:37\n",
            "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, labels_mean = 1.9630322, logits_mean = -0.056874916, loss = 50.066162, metric/ndcg@1 = 0.6685714, metric/ndcg@10 = 0.8381183, metric/ndcg@3 = 0.7301184, metric/ndcg@5 = 0.7809745\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: /tmp/ranking_model_dir/model.ckpt-14000\n",
            "INFO:tensorflow:global_step/sec: 18.6758\n",
            "INFO:tensorflow:loss = 80.72916, step = 14000 (5.354 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.7984\n",
            "INFO:tensorflow:loss = 55.10618, step = 14100 (2.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.4729\n",
            "INFO:tensorflow:loss = 61.91484, step = 14200 (2.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.0966\n",
            "INFO:tensorflow:loss = 46.20977, step = 14300 (2.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.0154\n",
            "INFO:tensorflow:loss = 54.245937, step = 14400 (2.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.1011\n",
            "INFO:tensorflow:loss = 60.151108, step = 14500 (2.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.8135\n",
            "INFO:tensorflow:loss = 54.700497, step = 14600 (2.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9505\n",
            "INFO:tensorflow:loss = 45.10563, step = 14700 (2.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.3953\n",
            "INFO:tensorflow:loss = 51.9403, step = 14800 (2.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.9908\n",
            "INFO:tensorflow:loss = 54.96768, step = 14900 (2.227 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 15000 into /tmp/ranking_model_dir/model.ckpt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Number of shuffles: 1\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-09-16T16:22:02Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-15000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-09-16-16:22:03\n",
            "INFO:tensorflow:Saving dict for global step 15000: global_step = 15000, labels_mean = 1.9630322, logits_mean = -0.064794704, loss = 50.056644, metric/ndcg@1 = 0.685, metric/ndcg@10 = 0.8365746, metric/ndcg@3 = 0.7347153, metric/ndcg@5 = 0.77785563\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: /tmp/ranking_model_dir/model.ckpt-15000\n",
            "INFO:tensorflow:Loss for final step: 50.081985.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'global_step': 15000,\n",
              "  'labels_mean': 1.9630322,\n",
              "  'logits_mean': -0.064794704,\n",
              "  'loss': 50.056644,\n",
              "  'metric/ndcg@1': 0.685,\n",
              "  'metric/ndcg@10': 0.8365746,\n",
              "  'metric/ndcg@3': 0.7347153,\n",
              "  'metric/ndcg@5': 0.77785563},\n",
              " [])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHFWbcERC3kG",
        "colab_type": "text"
      },
      "source": [
        "## Resultados POINTWISE con SIGMOID-CROSS-ENTROPY "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iupXiIxITWCH",
        "colab_type": "text"
      },
      "source": [
        "- 'global_step': 15000,\n",
        "- 'labels_mean': 1.9630322\n",
        "- 'logits_mean': 6237.247\n",
        "- 'loss': -6358.942\n",
        "- 'metric/ndcg@1': 0.5928572\n",
        "- 'metric/ndcg@10': 0.7942663\n",
        "- 'metric/ndcg@3': 0.67040014\n",
        "- 'metric/ndcg@5': 0.72173136"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdD1A2gEUE_w",
        "colab_type": "text"
      },
      "source": [
        "## Resultados PAIRWISE con PAIRWISE_LOGISTIC_LOSS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGhKOZqVUFu7",
        "colab_type": "text"
      },
      "source": [
        "- 'global_step': 15000,\n",
        "- 'labels_mean': 1.9630322,\n",
        "- 'logits_mean': -0.6500347,\n",
        "- 'loss': 0.91366893,\n",
        "- 'metric/ndcg@1': 0.6535715,\n",
        "- 'metric/ndcg@10': 0.8362243,\n",
        "- 'metric/ndcg@3': 0.73208094,\n",
        "- 'metric/ndcg@5': 0.7784201},"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch0lwEU6YH2m",
        "colab_type": "text"
      },
      "source": [
        "## Resultados LISTWISE con SOFTMAX_LOSS (listas de tamaño n=5) \n",
        "- 'global_step': 15000,\n",
        "- 'labels_mean': 1.9630322,\n",
        "- 'logits_mean': -0.08550994,\n",
        "- 'loss': 50.07819,\n",
        "- 'metric/ndcg@1': 0.68071425,\n",
        "- 'metric/ndcg@10': 0.83762825,\n",
        "- 'metric/ndcg@3': 0.7373218,\n",
        "- 'metric/ndcg@5': 0.7784797"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA6hB1sR-Qa2",
        "colab_type": "text"
      },
      "source": [
        "# Probar modelo ya entrenado para queries de ejemplo "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncKP-6bqcY5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6864bb94-02ca-4746-8a99-7c9c470cfeb0"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27syqZ1wlh7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_documents = pd.read_csv('drive/My Drive/tf-ranking/antique-collection.txt', sep='\\t', names=[\"doc_id\", 'text'])\n",
        "df_test_queries = pd.read_csv('drive/My Drive/tf-ranking/antique-test-queries.txt',names = ['query_id', 'text'],  sep='\\t') \n",
        "\n",
        "df_test_results = pd.read_csv('drive/My Drive/tf-ranking/antique-test.qrel',  sep=' ', names = ['query_id', 'query_name', 'doc_id', 'relevance']) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3-lI4kCrJsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_queries_names = {}\n",
        "dict_document_names = {}\n",
        "dict_query_results = {}\n",
        "\n",
        "for _id, text in zip(df_documents.doc_id, df_documents.text):\n",
        "  dict_document_names[_id] = text\n",
        "\n",
        "for _id, text in zip(df_test_queries.query_id, df_test_queries.text):\n",
        "  dict_queries_names[_id] = text\n",
        "\n",
        "for _id in df_test_results.query_id:\n",
        "  dict_query_results[_id] = []\n",
        "\n",
        "for _id, qid, relevance in zip(df_test_results.query_id, df_test_results.doc_id, df_test_results.relevance) :\n",
        "  dict_query_results[_id].append([qid, relevance])\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-mTyPLC-tus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b795d343-2b26-419c-8553-0748119530ae"
      },
      "source": [
        "set(df_test_results.query_id)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{8293,\n",
              " 23464,\n",
              " 34041,\n",
              " 78762,\n",
              " 100653,\n",
              " 103830,\n",
              " 143833,\n",
              " 159716,\n",
              " 172731,\n",
              " 204633,\n",
              " 204963,\n",
              " 224109,\n",
              " 225575,\n",
              " 229303,\n",
              " 312215,\n",
              " 354733,\n",
              " 387874,\n",
              " 402514,\n",
              " 421753,\n",
              " 443848,\n",
              " 456214,\n",
              " 474417,\n",
              " 481173,\n",
              " 484496,\n",
              " 551239,\n",
              " 558570,\n",
              " 654124,\n",
              " 667488,\n",
              " 676028,\n",
              " 707303,\n",
              " 714612,\n",
              " 746920,\n",
              " 761742,\n",
              " 765138,\n",
              " 785823,\n",
              " 788976,\n",
              " 821387,\n",
              " 823384,\n",
              " 849221,\n",
              " 851124,\n",
              " 896725,\n",
              " 922849,\n",
              " 949154,\n",
              " 953489,\n",
              " 1015624,\n",
              " 1017690,\n",
              " 1035857,\n",
              " 1063812,\n",
              " 1077370,\n",
              " 1082595,\n",
              " 1119420,\n",
              " 1152934,\n",
              " 1167882,\n",
              " 1199639,\n",
              " 1254390,\n",
              " 1262692,\n",
              " 1282199,\n",
              " 1287437,\n",
              " 1290612,\n",
              " 1292734,\n",
              " 1340574,\n",
              " 1351675,\n",
              " 1364894,\n",
              " 1373069,\n",
              " 1459749,\n",
              " 1477322,\n",
              " 1502604,\n",
              " 1509982,\n",
              " 1582877,\n",
              " 1607728,\n",
              " 1623623,\n",
              " 1663853,\n",
              " 1702151,\n",
              " 1783010,\n",
              " 1794677,\n",
              " 1821193,\n",
              " 1844896,\n",
              " 1850323,\n",
              " 1862795,\n",
              " 1866981,\n",
              " 1880028,\n",
              " 1937374,\n",
              " 1944018,\n",
              " 1957887,\n",
              " 1964316,\n",
              " 1968489,\n",
              " 1971899,\n",
              " 1977054,\n",
              " 2008017,\n",
              " 2018562,\n",
              " 2142044,\n",
              " 2180086,\n",
              " 2182052,\n",
              " 2192891,\n",
              " 2290758,\n",
              " 2291272,\n",
              " 2307305,\n",
              " 2309774,\n",
              " 2380990,\n",
              " 2382487,\n",
              " 2418598,\n",
              " 2443586,\n",
              " 2446614,\n",
              " 2452795,\n",
              " 2479423,\n",
              " 2484180,\n",
              " 2528767,\n",
              " 2529114,\n",
              " 2539741,\n",
              " 2551845,\n",
              " 2582920,\n",
              " 2592121,\n",
              " 2619912,\n",
              " 2634143,\n",
              " 2643507,\n",
              " 2713171,\n",
              " 2722241,\n",
              " 2783398,\n",
              " 2785579,\n",
              " 2795030,\n",
              " 2797224,\n",
              " 2799913,\n",
              " 2814599,\n",
              " 2814722,\n",
              " 2815090,\n",
              " 2838988,\n",
              " 2847807,\n",
              " 2862887,\n",
              " 2864267,\n",
              " 2892478,\n",
              " 2956570,\n",
              " 2976644,\n",
              " 3040435,\n",
              " 3074429,\n",
              " 3078448,\n",
              " 3155314,\n",
              " 3206998,\n",
              " 3239329,\n",
              " 3269759,\n",
              " 3278654,\n",
              " 3280768,\n",
              " 3295055,\n",
              " 3301173,\n",
              " 3313308,\n",
              " 3363149,\n",
              " 3369088,\n",
              " 3382736,\n",
              " 3385681,\n",
              " 3389038,\n",
              " 3396066,\n",
              " 3411123,\n",
              " 3496147,\n",
              " 3499881,\n",
              " 3507491,\n",
              " 3552010,\n",
              " 3554263,\n",
              " 3559048,\n",
              " 3577501,\n",
              " 3639660,\n",
              " 3640705,\n",
              " 3698636,\n",
              " 3714728,\n",
              " 3723508,\n",
              " 3778229,\n",
              " 3825386,\n",
              " 3872395,\n",
              " 3874326,\n",
              " 3910925,\n",
              " 3960080,\n",
              " 3971195,\n",
              " 3990512,\n",
              " 4003223,\n",
              " 4012558,\n",
              " 4018891,\n",
              " 4126337,\n",
              " 4153592,\n",
              " 4165406,\n",
              " 4185395,\n",
              " 4185501,\n",
              " 4190287,\n",
              " 4196421,\n",
              " 4197214,\n",
              " 4250296,\n",
              " 4256593,\n",
              " 4278201,\n",
              " 4283542,\n",
              " 4288761,\n",
              " 4311093,\n",
              " 4357460,\n",
              " 4365565,\n",
              " 4367654,\n",
              " 4372730,\n",
              " 4377861,\n",
              " 4385316,\n",
              " 4406669,\n",
              " 4448097,\n",
              " 4462511,\n",
              " 4467100,\n",
              " 4473137,\n",
              " 4473331}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv9ViLI6zHWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d0bcf5df-07fc-4b4d-e1f7-0b896a3240bc"
      },
      "source": [
        "# QUERY DE EJEMPLO \n",
        "QID = 143833\n",
        "\n",
        "print('QUERY TITLE: ')\n",
        "print(dict_queries_names[QID])\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QUERY TITLE: \n",
            "What is the difference between coolant and anti-freeze?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJfzA1NrqFLP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "44b39660-d517-422d-8f27-594d33e906ed"
      },
      "source": [
        "total_docs_query = len(df_test_results[df_test_results['query_id'] == QID])\n",
        "\n",
        "print('total documents for query: {}'.format(len(df_test_results[df_test_results['query_id'] == QID])))\n",
        "\n",
        "df_test_results[df_test_results['query_id'] == QID ].sort_values('relevance', ascending=False)\n"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total documents for query: 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_id</th>\n",
              "      <th>query_name</th>\n",
              "      <th>doc_id</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5611</th>\n",
              "      <td>143833</td>\n",
              "      <td>U0</td>\n",
              "      <td>143833_0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5625</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>143833_6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5614</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>143833_7</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5621</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>143833_2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5622</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>143833_5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5623</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>143833_4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5635</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>2404029_2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5633</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>1453706_9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5632</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>3977645_5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5630</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>158155_14</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5629</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>1453706_13</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5628</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>202603_8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5627</th>\n",
              "      <td>143833</td>\n",
              "      <td>E0</td>\n",
              "      <td>4032001_7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5626</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>211922_2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5636</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>3511244_1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5620</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>143833_3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5619</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>143833_1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5618</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>2580192_2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5615</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>2539741_0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5613</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>1130467_0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5612</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>4105530_10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5617</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>3769909_5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5631</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>1458356_0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5616</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>3542328_40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5634</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>1391621_5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5624</th>\n",
              "      <td>143833</td>\n",
              "      <td>Q0</td>\n",
              "      <td>3757501_4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      query_id query_name      doc_id  relevance\n",
              "5611    143833         U0    143833_0          4\n",
              "5625    143833         Q0    143833_6          4\n",
              "5614    143833         Q0    143833_7          4\n",
              "5621    143833         Q0    143833_2          4\n",
              "5622    143833         Q0    143833_5          3\n",
              "5623    143833         Q0    143833_4          3\n",
              "5635    143833         Q0   2404029_2          2\n",
              "5633    143833         Q0   1453706_9          2\n",
              "5632    143833         Q0   3977645_5          2\n",
              "5630    143833         Q0   158155_14          2\n",
              "5629    143833         Q0  1453706_13          2\n",
              "5628    143833         Q0    202603_8          2\n",
              "5627    143833         E0   4032001_7          2\n",
              "5626    143833         Q0    211922_2          2\n",
              "5636    143833         Q0   3511244_1          2\n",
              "5620    143833         Q0    143833_3          2\n",
              "5619    143833         Q0    143833_1          2\n",
              "5618    143833         Q0   2580192_2          2\n",
              "5615    143833         Q0   2539741_0          2\n",
              "5613    143833         Q0   1130467_0          2\n",
              "5612    143833         Q0  4105530_10          1\n",
              "5617    143833         Q0   3769909_5          1\n",
              "5631    143833         Q0   1458356_0          1\n",
              "5616    143833         Q0  3542328_40          1\n",
              "5634    143833         Q0   1391621_5          1\n",
              "5624    143833         Q0   3757501_4          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quNLjVAVs3k9",
        "colab_type": "text"
      },
      "source": [
        "### predecimos documentos relevantes para una query del test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWCiLcqtxYEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "94c5e919-f5ed-474a-8ab9-a0a1f0ea256b"
      },
      "source": [
        "# test set \n",
        "import warnings\n",
        "from operator import itemgetter\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "cont = 6 \n",
        "\n",
        "\n",
        "ranked_results = ''\n",
        "real_results = ''\n",
        "\n",
        "for x in ranker.predict(input_fn=lambda: input_fn(_TEST_DATA_PATH)):\n",
        "\n",
        "    ranking_list = [[y[0], id_] for id_, y in zip(x[0:total_docs_query], dict_query_results[QID])]\n",
        "  \n",
        "    ranked_results = sorted(ranking_list, key=lambda x: x[1], reverse=True)\n",
        "  \n",
        "    real_results = sorted(dict_query_results[QID], key=lambda x: x[1], reverse=True)\n",
        "  \n",
        "    cont +=1 \n",
        "    \n",
        "    if cont == 7:\n",
        "      break"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-15000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnvMSqJF0vdy",
        "colab_type": "text"
      },
      "source": [
        "## RESULTADOS PREDICHOS POR EL RANKER: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEs8_v0Qkt-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "a29cd8f3-356c-4a82-f267-d709c5cdacd1"
      },
      "source": [
        "print('QUERY: {}'.format(dict_queries_names[QID]))\n",
        "df_results = pd.DataFrame(ranked_results, columns = ['doc_id', 'score'])\n",
        "df_results['text'] = [dict_document_names[x] for x in df_results.doc_id]\n",
        "df_results\n"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QUERY: What is the difference between coolant and anti-freeze?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>score</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1130467_0</td>\n",
              "      <td>0.003900</td>\n",
              "      <td>I would check the \"Coolant Level Sensor\" first...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>143833_0</td>\n",
              "      <td>0.002804</td>\n",
              "      <td>The difference is, coolant is the liquid that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3769909_5</td>\n",
              "      <td>0.002679</td>\n",
              "      <td>i think your dog may have eaten chocolate or a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1458356_0</td>\n",
              "      <td>0.001905</td>\n",
              "      <td>drain the coolant out, drill a hole in the cen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1453706_9</td>\n",
              "      <td>0.001683</td>\n",
              "      <td>Water was commonly used in automobile radiator...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>143833_3</td>\n",
              "      <td>0.000987</td>\n",
              "      <td>While your at the store getting your coolant a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>143833_5</td>\n",
              "      <td>0.000832</td>\n",
              "      <td>There is no difference. It is the same substan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2404029_2</td>\n",
              "      <td>0.000826</td>\n",
              "      <td>Actually 2 ways. \"Old man\" way and the Right w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>143833_1</td>\n",
              "      <td>0.000657</td>\n",
              "      <td>It's the same thing dude!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3977645_5</td>\n",
              "      <td>0.000462</td>\n",
              "      <td>different oils freeze at different points</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3757501_4</td>\n",
              "      <td>0.000450</td>\n",
              "      <td>Emergency Vet Hospital NOW!  She could have go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>143833_2</td>\n",
              "      <td>0.000348</td>\n",
              "      <td>They are the same thing. It just does two jobs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1453706_13</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>Water is used ONLY if the proper coolant is un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>202603_8</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>Everything will freeze if you turn the tempera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4032001_7</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>After engine shut down coolant temperatures ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>143833_6</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>Coolant IS the more proper term.  Ethylene gly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>211922_2</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>also, make sure that no coolant is dripping fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>158155_14</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>the cheapest and easy way to tell is to make s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3511244_1</td>\n",
              "      <td>-0.002168</td>\n",
              "      <td>I DON'T BELIEVE ETHYLENE GLYCOL (ANTI-FREEZE) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>143833_7</td>\n",
              "      <td>-0.012365</td>\n",
              "      <td>Coolant is the liquid in the radiator.  It may...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>143833_4</td>\n",
              "      <td>-0.094909</td>\n",
              "      <td>just make sure whatever you're using says \"for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2539741_0</td>\n",
              "      <td>-0.160086</td>\n",
              "      <td>i hate to tell you this,but you blown a head g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2580192_2</td>\n",
              "      <td>-0.185705</td>\n",
              "      <td>It may be your fluids especially antifreeze co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1391621_5</td>\n",
              "      <td>-0.216749</td>\n",
              "      <td>Even if the  sea becomes frozen the fishes in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3542328_40</td>\n",
              "      <td>-0.330755</td>\n",
              "      <td>Pee-pee, meat tenderizer,prep shaving cream, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>4105530_10</td>\n",
              "      <td>-0.334845</td>\n",
              "      <td>Anti-freeze</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        doc_id     score                                               text\n",
              "0    1130467_0  0.003900  I would check the \"Coolant Level Sensor\" first...\n",
              "1     143833_0  0.002804  The difference is, coolant is the liquid that ...\n",
              "2    3769909_5  0.002679  i think your dog may have eaten chocolate or a...\n",
              "3    1458356_0  0.001905  drain the coolant out, drill a hole in the cen...\n",
              "4    1453706_9  0.001683  Water was commonly used in automobile radiator...\n",
              "5     143833_3  0.000987  While your at the store getting your coolant a...\n",
              "6     143833_5  0.000832  There is no difference. It is the same substan...\n",
              "7    2404029_2  0.000826  Actually 2 ways. \"Old man\" way and the Right w...\n",
              "8     143833_1  0.000657                          It's the same thing dude!\n",
              "9    3977645_5  0.000462          different oils freeze at different points\n",
              "10   3757501_4  0.000450  Emergency Vet Hospital NOW!  She could have go...\n",
              "11    143833_2  0.000348  They are the same thing. It just does two jobs...\n",
              "12  1453706_13  0.000126  Water is used ONLY if the proper coolant is un...\n",
              "13    202603_8  0.000124  Everything will freeze if you turn the tempera...\n",
              "14   4032001_7  0.000123  After engine shut down coolant temperatures ac...\n",
              "15    143833_6  0.000122  Coolant IS the more proper term.  Ethylene gly...\n",
              "16    211922_2  0.000122  also, make sure that no coolant is dripping fr...\n",
              "17   158155_14  0.000027  the cheapest and easy way to tell is to make s...\n",
              "18   3511244_1 -0.002168  I DON'T BELIEVE ETHYLENE GLYCOL (ANTI-FREEZE) ...\n",
              "19    143833_7 -0.012365  Coolant is the liquid in the radiator.  It may...\n",
              "20    143833_4 -0.094909  just make sure whatever you're using says \"for...\n",
              "21   2539741_0 -0.160086  i hate to tell you this,but you blown a head g...\n",
              "22   2580192_2 -0.185705  It may be your fluids especially antifreeze co...\n",
              "23   1391621_5 -0.216749  Even if the  sea becomes frozen the fishes in ...\n",
              "24  3542328_40 -0.330755  Pee-pee, meat tenderizer,prep shaving cream, a...\n",
              "25  4105530_10 -0.334845                                        Anti-freeze"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnS2ksFD0z7-",
        "colab_type": "text"
      },
      "source": [
        "## RESULTADOS REALES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3OP4L4nyAEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "97c8fe44-e383-4091-bbdb-5b4ffa522956"
      },
      "source": [
        "print('QUERY: {}'.format(dict_queries_names[QID]))\n",
        "df_ground_truth = pd.DataFrame(real_results, columns = ['doc_id', 'relevance'])\n",
        "df_ground_truth['text'] = [dict_document_names[x] for x in df_ground_truth.doc_id]\n",
        "df_ground_truth"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QUERY: What is the difference between coolant and anti-freeze?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>relevance</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>143833_0</td>\n",
              "      <td>4</td>\n",
              "      <td>The difference is, coolant is the liquid that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>143833_7</td>\n",
              "      <td>4</td>\n",
              "      <td>Coolant is the liquid in the radiator.  It may...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>143833_2</td>\n",
              "      <td>4</td>\n",
              "      <td>They are the same thing. It just does two jobs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>143833_6</td>\n",
              "      <td>4</td>\n",
              "      <td>Coolant IS the more proper term.  Ethylene gly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>143833_5</td>\n",
              "      <td>3</td>\n",
              "      <td>There is no difference. It is the same substan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>143833_4</td>\n",
              "      <td>3</td>\n",
              "      <td>just make sure whatever you're using says \"for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1130467_0</td>\n",
              "      <td>2</td>\n",
              "      <td>I would check the \"Coolant Level Sensor\" first...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2539741_0</td>\n",
              "      <td>2</td>\n",
              "      <td>i hate to tell you this,but you blown a head g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2580192_2</td>\n",
              "      <td>2</td>\n",
              "      <td>It may be your fluids especially antifreeze co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>143833_1</td>\n",
              "      <td>2</td>\n",
              "      <td>It's the same thing dude!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>143833_3</td>\n",
              "      <td>2</td>\n",
              "      <td>While your at the store getting your coolant a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>211922_2</td>\n",
              "      <td>2</td>\n",
              "      <td>also, make sure that no coolant is dripping fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4032001_7</td>\n",
              "      <td>2</td>\n",
              "      <td>After engine shut down coolant temperatures ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>202603_8</td>\n",
              "      <td>2</td>\n",
              "      <td>Everything will freeze if you turn the tempera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1453706_13</td>\n",
              "      <td>2</td>\n",
              "      <td>Water is used ONLY if the proper coolant is un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>158155_14</td>\n",
              "      <td>2</td>\n",
              "      <td>the cheapest and easy way to tell is to make s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3977645_5</td>\n",
              "      <td>2</td>\n",
              "      <td>different oils freeze at different points</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1453706_9</td>\n",
              "      <td>2</td>\n",
              "      <td>Water was commonly used in automobile radiator...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2404029_2</td>\n",
              "      <td>2</td>\n",
              "      <td>Actually 2 ways. \"Old man\" way and the Right w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3511244_1</td>\n",
              "      <td>2</td>\n",
              "      <td>I DON'T BELIEVE ETHYLENE GLYCOL (ANTI-FREEZE) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>4105530_10</td>\n",
              "      <td>1</td>\n",
              "      <td>Anti-freeze</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3542328_40</td>\n",
              "      <td>1</td>\n",
              "      <td>Pee-pee, meat tenderizer,prep shaving cream, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3769909_5</td>\n",
              "      <td>1</td>\n",
              "      <td>i think your dog may have eaten chocolate or a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3757501_4</td>\n",
              "      <td>1</td>\n",
              "      <td>Emergency Vet Hospital NOW!  She could have go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1458356_0</td>\n",
              "      <td>1</td>\n",
              "      <td>drain the coolant out, drill a hole in the cen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1391621_5</td>\n",
              "      <td>1</td>\n",
              "      <td>Even if the  sea becomes frozen the fishes in ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        doc_id  relevance                                               text\n",
              "0     143833_0          4  The difference is, coolant is the liquid that ...\n",
              "1     143833_7          4  Coolant is the liquid in the radiator.  It may...\n",
              "2     143833_2          4  They are the same thing. It just does two jobs...\n",
              "3     143833_6          4  Coolant IS the more proper term.  Ethylene gly...\n",
              "4     143833_5          3  There is no difference. It is the same substan...\n",
              "5     143833_4          3  just make sure whatever you're using says \"for...\n",
              "6    1130467_0          2  I would check the \"Coolant Level Sensor\" first...\n",
              "7    2539741_0          2  i hate to tell you this,but you blown a head g...\n",
              "8    2580192_2          2  It may be your fluids especially antifreeze co...\n",
              "9     143833_1          2                          It's the same thing dude!\n",
              "10    143833_3          2  While your at the store getting your coolant a...\n",
              "11    211922_2          2  also, make sure that no coolant is dripping fr...\n",
              "12   4032001_7          2  After engine shut down coolant temperatures ac...\n",
              "13    202603_8          2  Everything will freeze if you turn the tempera...\n",
              "14  1453706_13          2  Water is used ONLY if the proper coolant is un...\n",
              "15   158155_14          2  the cheapest and easy way to tell is to make s...\n",
              "16   3977645_5          2          different oils freeze at different points\n",
              "17   1453706_9          2  Water was commonly used in automobile radiator...\n",
              "18   2404029_2          2  Actually 2 ways. \"Old man\" way and the Right w...\n",
              "19   3511244_1          2  I DON'T BELIEVE ETHYLENE GLYCOL (ANTI-FREEZE) ...\n",
              "20  4105530_10          1                                        Anti-freeze\n",
              "21  3542328_40          1  Pee-pee, meat tenderizer,prep shaving cream, a...\n",
              "22   3769909_5          1  i think your dog may have eaten chocolate or a...\n",
              "23   3757501_4          1  Emergency Vet Hospital NOW!  She could have go...\n",
              "24   1458356_0          1  drain the coolant out, drill a hole in the cen...\n",
              "25   1391621_5          1  Even if the  sea becomes frozen the fishes in ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hFXjOSK1T5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}